{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chronological Development of Word Embeddings\n",
        "\n",
        "---\n",
        "\n",
        "## 1️⃣ Linguistic & Theoretical Origins (1950s–1970s)\n",
        "\n",
        "- **1953 – Luhn, H. P.**  \n",
        "  *A New Method of Recording and Searching Information* — established computational text search foundations.\n",
        "\n",
        "- **1957 – Firth, J. R.**  \n",
        "  *A Synopsis of Linguistic Theory 1930–1955.*  \n",
        "  → Introduced the **distributional hypothesis:**  \n",
        "  > “You shall know a word by the company it keeps.”\n",
        "\n",
        "- **1957 – Osgood, C. E. et al.**  \n",
        "  *The Measurement of Meaning.*  \n",
        "  → Proposed **semantic differential scales**, precursors to semantic spaces.\n",
        "\n",
        "- **1962 – Salton, G.**  \n",
        "  *Some Experiments in the Generation of Word and Document Associations.*  \n",
        "  → Developed the **Vector Space Model (VSM)** for information retrieval.\n",
        "\n",
        "- **1975 – Salton, Wong & Yang.**  \n",
        "  *A Vector Space Model for Automatic Indexing.*  \n",
        "  → Unified term and document vectors into measurable semantic similarity.\n",
        "\n",
        "---\n",
        "\n",
        "## 2️⃣ Statistical Semantics & Latent Representation (1980s–1990s)\n",
        "\n",
        "- **Late 1980s – Deerwester et al.**  \n",
        "  Developed **Latent Semantic Analysis (LSA)** with **SVD** for reduced-dimensional semantic spaces.\n",
        "\n",
        "- **2000 – Kanerva, Kristoferson & Holst.**  \n",
        "  *Random Indexing of Text Samples for LSA.*  \n",
        "  → Scalable alternative to SVD.\n",
        "\n",
        "- **2001 – Karlgren & Sahlgren.**  \n",
        "  *From Words to Understanding.*  \n",
        "  → Refined distributional semantics.\n",
        "\n",
        "- **2005 – Sahlgren.**  \n",
        "  *An Introduction to Random Indexing.*  \n",
        "  → Formalized the **Random Indexing** technique.\n",
        "\n",
        "- **2008 – Sahlgren et al.**  \n",
        "  *Permutations as a Means to Encode Order in Word Space.*  \n",
        "  → Introduced order sensitivity into semantic spaces.\n",
        "\n",
        "---\n",
        "\n",
        "## 3️⃣ Neural Revolution: Distributed Representations (2000–2006)\n",
        "\n",
        "- **2000–2003 – Bengio et al.**  \n",
        "  *A Neural Probabilistic Language Model.*  \n",
        "  → First **neural network–based language model** producing **dense word vectors**.\n",
        "\n",
        "- **2002 – Vinkourov et al.**  \n",
        "  *Cross-Language Correlation Analysis.*  \n",
        "  → Introduced **bilingual embeddings**.\n",
        "\n",
        "- **2004 – Lavelli et al.**  \n",
        "  *Distributional Term Representations.*  \n",
        "  → Compared early embedding architectures.\n",
        "\n",
        "- **2005 – Morin & Bengio.**  \n",
        "  *Hierarchical Probabilistic Neural Network Language Model.*  \n",
        "  → Introduced **hierarchical softmax** for efficient large-vocabulary learning.\n",
        "\n",
        "- **2006 – Bengio et al.**  \n",
        "  Consolidated **distributed representation** as a core NLP foundation.\n",
        "\n",
        "---\n",
        "\n",
        "## 4️⃣ Deep & Scalable Neural Embeddings (2008–2013)\n",
        "\n",
        "- **2008 – Collobert & Weston.**  \n",
        "  *A Unified Architecture for NLP.*  \n",
        "  → Showed **deep multitask learning** produces reusable embeddings.\n",
        "\n",
        "- **2009 – Mnih & Hinton.**  \n",
        "  *A Scalable Hierarchical Distributed Language Model.*\n",
        "\n",
        "- **2010 – Reisinger & Mooney.**  \n",
        "  *Multi-Prototype Vector-Space Models of Word Meaning.*  \n",
        "  → Introduced **multi-sense embeddings**.\n",
        "\n",
        "- **2012 – Huang, Socher & Ng.**  \n",
        "  Combined **global context** and **word prototypes**.\n",
        "\n",
        "- **2013 – Mikolov et al.**  \n",
        "  *Distributed Representations of Words and Phrases and Their Compositionality.*  \n",
        "  → **Word2Vec** (CBOW & Skip-gram) — scalable, efficient, industry-changing.\n",
        "\n",
        "- **2013 – Lebret & Collobert.**  \n",
        "  *Word Embeddings through Hellinger PCA.*\n",
        "\n",
        "- **2014 – Levy & Goldberg.**  \n",
        "  *Neural Word Embedding as Implicit Matrix Factorization.*  \n",
        "  → Linked Word2Vec with **matrix factorization** theory.\n",
        "\n",
        "---\n",
        "\n",
        "## 5️⃣ Multi-Sense & Contextual Representation (2014–2019)\n",
        "\n",
        "- **2014 – Neelakantan et al.**  \n",
        "  *Efficient Non-Parametric Estimation of Multiple Embeddings per Word.*\n",
        "\n",
        "- **2015 – Li & Jurafsky.**  \n",
        "  *Do Multi-Sense Embeddings Improve NLU?* — empirical evaluation.\n",
        "\n",
        "- **2015 – Asgari & Mofrad.**  \n",
        "  *Continuous Distributed Representation of Biological Sequences.*  \n",
        "  → **BioVec / ProtVec / GeneVec**.\n",
        "\n",
        "- **2015 – Kiros et al.**  \n",
        "  *Skip-Thought Vectors.*  \n",
        "  → Sentence-level embeddings.\n",
        "\n",
        "- **2016 – Bolukbasi et al.**  \n",
        "  *Man is to Computer Programmer as Woman is to Homemaker?*  \n",
        "  → Uncovered **gender bias** in embeddings.\n",
        "\n",
        "- **2018 – Akbik et al.**  \n",
        "  *Contextual String Embeddings for Sequence Labeling (Flair).*  \n",
        "\n",
        "- **2018 – Camacho-Collados & Pilehvar.**  \n",
        "  *From Word to Sense Embeddings: A Survey.*\n",
        "\n",
        "- **2018 – Ruas et al.**  \n",
        "  *Multi-Sense Embeddings via Word Sense Disambiguation.*\n",
        "\n",
        "- **2019 – Devlin et al.**  \n",
        "  *BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.*  \n",
        "  → Contextual embeddings revolution — **meaning depends on context**.\n",
        "\n",
        "- **2019 – Reimers & Gurevych.**  \n",
        "  *Sentence-BERT.*  \n",
        "  → Siamese/triplet network adaptation of BERT.\n",
        "\n",
        "- **2019 – Reif et al.**  \n",
        "  *Visualizing and Measuring the Geometry of BERT.*\n",
        "\n",
        "---\n",
        "\n",
        "## 6️⃣ Specialized & Applied Embeddings (2015–2021)\n",
        "\n",
        "- **2015 – Ghassemi et al.**  \n",
        "  *Clinical Sentiment Vector Representations.*  \n",
        "  → Domain adaptation to medicine.\n",
        "\n",
        "- **2021 – Rabii & Cook.**  \n",
        "  *Word Embeddings of Gameplay Data.*  \n",
        "  → Applied embeddings to **game dynamics**.\n",
        "\n",
        "- **2021 – Lucy & Bamman.**  \n",
        "  *Characterizing English Variation Across Social Media with BERT.*  \n",
        "  → Sociolinguistic contextualization.\n",
        "\n",
        "---\n",
        "\n",
        "## 7️⃣ Ethical, Fairness & Bias Mitigation (2016–2022)\n",
        "\n",
        "- **2016 – Bolukbasi et al.**  \n",
        "  Revealed embedding bias — foundation for **fairness-aware NLP**.\n",
        "\n",
        "- **2017 – Zhao et al.**  \n",
        "  *Reducing Gender Bias Amplification.*  \n",
        "\n",
        "- **2018 – Zhao et al.**  \n",
        "  *Learning Gender-Neutral Word Embeddings.*\n",
        "\n",
        "- **2020 – Dieng, Ruiz & Blei.**  \n",
        "  *Topic Modeling in Embedding Spaces.*\n",
        "\n",
        "- **2022 – Petreski & Hashim.**  \n",
        "  *Word Embeddings Are Biased. But Whose Bias Are They Reflecting?*  \n",
        "\n",
        "---\n",
        "\n",
        "## 8️⃣ Software Ecosystem\n",
        "\n",
        "- **Word2Vec** – Google (Mikolov et al., 2013)  \n",
        "- **GloVe** – Stanford (Pennington et al., 2014)  \n",
        "- **fastText** – Facebook AI Research  \n",
        "- **ELMo** – AllenNLP (Peters et al., 2018)  \n",
        "- **Flair** – Akbik et al. (2018)  \n",
        "- **BERT / Sentence-BERT** – Google & UKP Lab (2019)  \n",
        "- Frameworks: **Gensim**, **Indra**, **Deeplearning4j**\n",
        "\n",
        "Visualization methods: **PCA**, **t-SNE**, **Embedding Projector (2018)**.\n",
        "\n",
        "---\n",
        "\n",
        "## Summary Timeline\n",
        "\n",
        "| Period | Core Idea | Representative Works |\n",
        "|--------|------------|----------------------|\n",
        "| 1950s–1970s | Distributional hypothesis, VSM | Firth (1957), Salton (1975) |\n",
        "| 1980s–1990s | Latent semantics | Deerwester (1988), Sahlgren (2005) |\n",
        "| 2000–2006 | Neural probabilistic LM | Bengio (2003), Morin & Bengio (2005) |\n",
        "| 2008–2013 | Deep scalable embeddings | Collobert (2008), Mikolov (2013) |\n",
        "| 2014–2019 | Contextual & multi-sense | Devlin (2019), Reimers (2019) |\n",
        "| 2015–2021 | Applied/domain embeddings | Asgari (2015), Lucy (2021) |\n",
        "| 2016–2022 | Ethical & fairness research | Bolukbasi (2016), Petreski (2022) |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "bvxGJEdgm6XB"
      }
    }
  ]
}