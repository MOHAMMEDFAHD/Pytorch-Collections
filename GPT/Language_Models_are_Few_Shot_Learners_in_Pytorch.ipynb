{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# “Language Models are Few-Shot Learners” (Brown et al., 2020, GPT-3)\n",
        "\n",
        "# https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf\n",
        "\n",
        "\n",
        "\n",
        "## Abstract\n",
        "The paper introduces **GPT-3**, a 175B parameter autoregressive Transformer language model, the largest at its release. GPT-3 demonstrates that scaling language models leads to strong **few-shot performance**, often rivaling or surpassing fine-tuned state-of-the-art (SOTA) systems—without task-specific training. It achieves competitive results across **translation, question answering, cloze tasks, and reasoning**, but also reveals significant **limitations in consistency, fairness, and efficiency**.\n",
        "\n",
        "---\n",
        "\n",
        "## Problems\n",
        "- **Dependence on task-specific fine-tuning:** Prior NLP advances required large supervised datasets and fine-tuned models.  \n",
        "- **Limited zero-/few-shot generalization:** Earlier models (e.g., GPT-2) showed promise but trailed behind supervised baselines.  \n",
        "- **Unclear scalability:** It was unknown whether scaling laws would hold at the extreme scale of 100B+ parameters.  \n",
        "- **Ethical risks and bias:** Large generative models raised concerns about misuse, harmful outputs, and bias amplification.  \n",
        "\n",
        "---\n",
        "\n",
        "## Proposed Solutions\n",
        "1. Train a **175B parameter Transformer LM** using next-word prediction, extending scaling laws by two orders of magnitude.  \n",
        "2. Explore **zero-shot, one-shot, and few-shot prompting** instead of supervised fine-tuning.  \n",
        "3. Evaluate systematically across diverse NLP benchmarks to test generalization without parameter updates.  \n",
        "\n",
        "---\n",
        "\n",
        "## Purpose\n",
        "To test whether **extreme scaling alone** can enable few-shot multitask learning capabilities approaching or surpassing **fine-tuned models**, thereby reducing reliance on supervised datasets.\n",
        "\n",
        "---\n",
        "\n",
        "## Methodology\n",
        "- **Model:** Decoder-only Transformer, architecture similar to GPT-2 but scaled from **125M → 175B parameters**.  \n",
        "- **Training Data:** ~570GB mix of CommonCrawl (filtered), WebText2, Books1/2, and Wikipedia.  \n",
        "- **Evaluation Settings:**  \n",
        "  - **Zero-shot:** Only a natural language description of the task.  \n",
        "  - **One-shot:** Single in-context example.  \n",
        "  - **Few-shot:** 10–100 in-context examples, no parameter updates.  \n",
        "- **Benchmarks:**  \n",
        "  - **Language modeling:** PTB, LAMBADA  \n",
        "  - **Question answering:** CoQA, TriviaQA, Natural Questions  \n",
        "  - **Reasoning:** ARC, DROP  \n",
        "  - **Translation:** WMT (En–Fr, En–De, etc.)  \n",
        "  - **SuperGLUE:** suite of diverse NLU tasks  \n",
        "\n",
        "---\n",
        "\n",
        "## Results\n",
        "- **Language modeling:** New SOTA on PTB and LAMBADA; few-shot GPT-3 improved **LAMBADA accuracy by +18%** over prior SOTA.  \n",
        "- **QA:** Few-shot GPT-3 scored **71.2% on TriviaQA (SOTA)** and strong results on CoQA (**85 F1, near human-level**).  \n",
        "- **Reasoning:** Underperformed on ARC and DROP; struggled with symbolic reasoning compared to specialized models.  \n",
        "- **Translation:** Outperformed prior unsupervised MT methods but lagged behind supervised MT, especially for low-resource languages.  \n",
        "- **SuperGLUE:** Few-shot GPT-3 achieved **71.8**, competitive with **BERT-large**, but below fine-tuned **T5**.  \n",
        "- **Human evaluation:** GPT-3’s generated news articles were nearly indistinguishable from real ones (**52% detection, chance-level**).  \n",
        "- **Bias analysis:** Outputs exhibited strong gender, racial, and religious biases, reflecting stereotypes in training data.  \n",
        "\n",
        "---\n",
        "\n",
        "## Conclusions\n",
        "- **Scaling works:** Performance improved smoothly with model size, confirming scaling laws.  \n",
        "- **Few-shot learning is viable:** GPT-3 often matched or exceeded fine-tuned models in **few-shot** settings, validating **task-agnostic generalization**.  \n",
        "- **Limitations:** Weakness in fine-grained reasoning, repetition, incoherence in long outputs, and significant **social biases**.  \n",
        "- **Broader impact:** GPT-3 advanced general-purpose NLP capabilities but magnified ethical concerns around **bias, disinformation, misuse, and environmental cost**.  \n",
        "\n",
        "---\n",
        "\n",
        "## Key Takeaway\n",
        "GPT-3 confirmed the **power of scale**: larger models are better few-shot learners, reducing the need for supervised fine-tuning. However, it also highlighted the growing importance of addressing **bias, misuse, and sustainability** in AI systems.\n"
      ],
      "metadata": {
        "id": "jjsF2OXnTNb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mathematical and Statistical Content of “Language Models are Few-Shot Learners” (Brown et al., 2020, GPT-3)\n",
        "\n",
        "## 1. Language Modeling Objective\n",
        "GPT-3 is a **causal language model**:\n",
        "\n",
        "$$\n",
        "P(u) = \\prod_{i=1}^n P(u_i \\mid u_1, u_2, \\dots, u_{i-1}; \\Theta)\n",
        "$$\n",
        "\n",
        "- \\(u_i\\): token at position \\(i\\).  \n",
        "- \\(\\Theta\\): model parameters (175B).  \n",
        "\n",
        "**Role:** Predict the next token given all prior tokens. Training maximizes this joint probability across large-scale text data.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Training Loss: Negative Log-Likelihood\n",
        "The loss function is the **negative log-likelihood (NLL)**:\n",
        "\n",
        "$$\n",
        "L = -\\frac{1}{N} \\sum_{i=1}^N \\log P(u_i \\mid u_{<i}; \\Theta)\n",
        "$$\n",
        "\n",
        "- Equivalent to **cross-entropy loss**.  \n",
        "- **Role:** Encourages the model to assign high probability to the correct next token.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Perplexity\n",
        "**Perplexity (PPL)** measures predictive uncertainty:\n",
        "\n",
        "$$\n",
        "\\text{PPL} = \\exp\\!\\left(-\\frac{1}{N} \\sum_{i=1}^N \\log P(u_i)\\right)\n",
        "$$\n",
        "\n",
        "- **Interpretation:** How “surprised” the model is by the test set.  \n",
        "- **Lower PPL = better predictive performance.**  \n",
        "- **Usage in GPT-3:** Evaluated on PTB, LAMBADA, and other LM benchmarks.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Scaling Laws (Empirical Regularity)\n",
        "Model performance improves smoothly with **scale**:\n",
        "\n",
        "$$\n",
        "\\text{Loss}(N) \\approx a N^{-\\alpha} + b, \\quad \\alpha > 0\n",
        "$$\n",
        "\n",
        "- \\(N\\): scale of data, parameters, or compute.  \n",
        "- **Finding:** Larger models and more data yield **predictable, consistent improvements**.  \n",
        "- **Role:** Justifies GPT-3’s size (175B parameters).\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Evaluation Metrics (Task-Specific)\n",
        "GPT-3 is tested in **zero-, one-, and few-shot settings** using established statistical metrics:\n",
        "\n",
        "- **Accuracy (%)**: Multiple-choice reasoning (ARC, Winograd).  \n",
        "- **F1 score**: Span-based QA (CoQA).  \n",
        "- **BLEU**: Translation (WMT).  \n",
        "- **ROUGE**: Summarization (CNN/Daily Mail).  \n",
        "- **SuperGLUE score**: Composite benchmark.  \n",
        "- **Human evaluation**: News article realism (detection ~52%, chance-level).\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Few-Shot In-Context Learning as Conditional Probability\n",
        "Few-shot learning is framed as **conditioning on demonstrations**:\n",
        "\n",
        "Example prompt for translation:\n",
        "\n"
      ],
      "metadata": {
        "id": "WfJq2y1LUHmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "====================================================================\n",
        "                         GPT-3 ARCHITECTURE\n",
        "====================================================================\n",
        "\n",
        "                        INPUT & TOKENIZATION\n",
        "                        ---------------------\n",
        "\n",
        "   [ Raw Text Prompt ]\n",
        "          |\n",
        "          v\n",
        "   Byte-Pair Encoding (BPE) → ~50k vocabulary\n",
        "          |\n",
        "          v\n",
        "   +---------------------------------------------------+\n",
        "   |  Token Embeddings (W_e)                           |\n",
        "   +---------------------------------------------------+\n",
        "          |\n",
        "          v\n",
        "   +---------------------------------------------------+\n",
        "   |  Positional Embeddings (W_p)                      |\n",
        "   +---------------------------------------------------+\n",
        "          |\n",
        "          v\n",
        "   [ Input Representation h^0 = U W_e + W_p ]\n",
        "\n",
        "====================================================================\n",
        "                  TRANSFORMER DECODER STACK (175B)\n",
        "                  ---------------------------------\n",
        "\n",
        "   Repeated for L = 96 layers (largest GPT-3 model)\n",
        "\n",
        "   ┌─────────────────────────────────────────────────────────────┐\n",
        "   │   Transformer Block l                                       │\n",
        "   │                                                             │\n",
        "   │   +------------------+     +----------------------------+   │\n",
        "   │   | Masked Multi-    |     |  Position-wise Feed-       |   │\n",
        "   │   | Head Attention   |     |  Forward Network           |   │\n",
        "   │   +------------------+     +----------------------------+   │\n",
        "   │            |                              |                │\n",
        "   │   Residual + LayerNorm          Residual + LayerNorm        │\n",
        "   └─────────────────────────────────────────────────────────────┘\n",
        "                          |\n",
        "                          v\n",
        "   [ Final Hidden State h^n ]\n",
        "\n",
        "====================================================================\n",
        "                        OUTPUT DISTRIBUTION\n",
        "                        -------------------\n",
        "\n",
        "   +---------------------------------------------------+\n",
        "   |  Linear Projection (weight-tied with W_e^T)       |\n",
        "   +---------------------------------------------------+\n",
        "          |\n",
        "          v\n",
        "   +---------------------------------------------------+\n",
        "   |  Softmax → Probability distribution over vocab    |\n",
        "   |  P(next token | context)                          |\n",
        "   +---------------------------------------------------+\n",
        "\n",
        "====================================================================\n",
        "               ZERO-SHOT / ONE-SHOT / FEW-SHOT LEARNING\n",
        "               ----------------------------------------\n",
        "\n",
        "   Instead of parameter updates, GPT-3 conditions on *prompts*:\n",
        "\n",
        "   Zero-shot:\n",
        "     \"Translate English to French: house →\"\n",
        "          → model generates continuation.\n",
        "\n",
        "   One-shot:\n",
        "     \"Translate English to French:\n",
        "      cat → chat\n",
        "      house →\"\n",
        "          → model generates \"maison\".\n",
        "\n",
        "   Few-shot:\n",
        "     \"Translate English to French:\n",
        "      dog → chien\n",
        "      cat → chat\n",
        "      house → maison\n",
        "      car →\"\n",
        "          → model generates \"voiture\".\n",
        "\n",
        "   In all cases, learning occurs via in-context conditioning.\n",
        "\n",
        "====================================================================\n",
        "                          TRAINING OBJECTIVE\n",
        "                          ------------------\n",
        "\n",
        "   Next-token prediction:\n",
        "     L = - Σ log P(u_i | u_<i>, Θ)\n",
        "\n",
        "   Evaluation metric:\n",
        "     Perplexity = exp(- (1/N) Σ log P(u_i))\n",
        "\n",
        "   Scaling law (empirical):\n",
        "     Loss(N) ≈ aN^(-α) + b\n",
        "     (performance improves smoothly with more parameters/data)\n",
        "\n",
        "====================================================================\n",
        "```"
      ],
      "metadata": {
        "id": "GM3jxYFJUMww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Table: Problems, Limitations, and Proposed Solutions in GPT-3 (Brown et al., 2020)\n",
        "\n",
        "| **Key Problems / Research Gaps**   | **How These Issues Limit Prior Work**                                                                 | **Proposed Solutions in This Paper**                                                                 |\n",
        "|------------------------------------|--------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|\n",
        "| **Dependence on task-specific fine-tuning** | Models required large labeled datasets and retraining for each task, making them costly and inflexible. | Train a **single massive autoregressive Transformer (175B parameters)** with next-token prediction only, eliminating the need for fine-tuning. |\n",
        "| **Weak zero-/few-shot performance** | Earlier models (e.g., GPT-2) could not reliably generalize to unseen tasks and underperformed supervised baselines. | Use **natural language prompts** for zero-, one-, and few-shot evaluation, testing whether scale alone yields robust in-context learning. |\n",
        "| **Unclear effect of extreme scaling** | Previous research only tested up to **1.5B parameters**, leaving it unknown if scaling benefits persist at much larger orders. | Extend **scaling laws by two orders of magnitude (125M → 175B parameters)**, empirically verifying smooth performance improvements. |\n",
        "| **Limited cross-task generalization** | Fine-tuned systems were strong on individual benchmarks but failed to handle diverse NLP tasks without retraining. | Benchmark GPT-3 across **translation, QA, cloze tasks, reasoning, and SuperGLUE** in prompt-based settings, demonstrating broad multi-task ability. |\n",
        "| **Ethical and societal risks** | Prior LMs already showed bias, stereotyping, and potential for harmful misuse; risks intensify with scale. | Provide **bias analysis** and emphasize **responsible deployment**, highlighting fairness, consistency, and societal impact considerations. |\n",
        "\n",
        "---\n",
        "\n",
        "### Summary\n",
        "GPT-3 was explicitly designed to overcome the **limitations of fine-tuning-based systems** and **smaller-scale models**.  \n",
        "Its solutions—**massive scaling** plus **prompt-based in-context learning**—enabled a shift from narrow, task-specific models toward a **general-purpose few-shot learner**, while simultaneously raising critical questions of **bias, ethics, and responsible use**.\n"
      ],
      "metadata": {
        "id": "8GnuDFx4VqUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contributions of GPT-3 (Brown et al., 2020) Relative to GPT-2 and Prior Models\n",
        "\n",
        "| **Area**                          | **Prior State (GPT-2 & Others)**                                                                 | **GPT-3 Contribution**                                                                                         | **Impact / Novelty**                                                                 |\n",
        "|-----------------------------------|--------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------|\n",
        "| **Scale of Model Parameters**     | GPT-2: 1.5B parameters. Scaling laws observed but untested at extreme sizes.                     | GPT-3: 175B parameters — two orders of magnitude larger.                                                       | Established that performance improvements persist smoothly with extreme scaling.       |\n",
        "| **Training Objective**            | Standard next-word prediction; combined sometimes with auxiliary tasks (e.g., LM + classification). | Retained a **single causal LM objective** (next-word prediction) at massive scale.                              | Demonstrated that **no auxiliary objectives are needed** to achieve broad generalization. |\n",
        "| **Learning Paradigm**             | GPT-2 required **fine-tuning** for strong downstream performance.                               | GPT-3 introduced **in-context learning** (zero-, one-, few-shot) using natural language prompts.                | Shifted paradigm: task adaptation via **prompting instead of parameter updates**.       |\n",
        "| **Task Generalization**           | GPT-2 showed modest zero-shot transfer but underperformed supervised baselines.                 | GPT-3 achieved **few-shot SOTA or near-SOTA** on translation, QA, cloze, and some reasoning tasks.              | Validated the idea of a **single model performing competitively across diverse tasks**. |\n",
        "| **Benchmark Results**             | Prior models dominated by **fine-tuned BERT/T5** variants.                                      | GPT-3 few-shot: SOTA on **LAMBADA, TriviaQA**, competitive on **SuperGLUE**, improved unsupervised MT.          | Proved that **scaling alone can rival fine-tuned systems** on many tasks.               |\n",
        "| **Human Evaluation**              | GPT-2 text was coherent but often shallow or repetitive.                                        | GPT-3 generated **news articles indistinguishable from human text** (~52% detection, chance-level).             | Marked a leap in **naturalness and fluency** of machine-generated text.                 |\n",
        "| **Bias and Ethical Risks**        | Known issues with bias and toxic outputs in GPT-2 and earlier models.                           | GPT-3 explicitly analyzed for **gender, racial, and religious stereotypes**; authors withheld full release.     | Raised visibility of **fairness, misuse, and safety** as central research challenges.   |\n",
        "\n",
        "---\n",
        "\n",
        "## Summary\n",
        "GPT-3’s **core contribution** was showing that **scale + in-context prompting** is sufficient to unlock broad **few-shot learning capabilities**, without supervised fine-tuning. This represented a paradigm shift from **task-specific models** to a **single, general-purpose language model**, while also surfacing critical discussions on **bias, ethics, and responsible deployment**.\n",
        "\n"
      ],
      "metadata": {
        "id": "QZXIwaidVluC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk6-o22VTIgd",
        "outputId": "c6489eaa-cc57-42df-8b6a-b765338d428a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss=3.6912, Accuracy=3.85%\n",
            "Epoch 2: Loss=3.2770, Accuracy=23.08%\n",
            "Epoch 3: Loss=3.0430, Accuracy=23.08%\n",
            "Epoch 4: Loss=2.6796, Accuracy=26.92%\n",
            "Epoch 5: Loss=2.5424, Accuracy=42.31%\n",
            "Epoch 6: Loss=2.1444, Accuracy=50.00%\n",
            "Epoch 7: Loss=2.0662, Accuracy=76.92%\n",
            "Epoch 8: Loss=1.7313, Accuracy=76.92%\n",
            "Epoch 9: Loss=1.4366, Accuracy=88.46%\n",
            "Epoch 10: Loss=1.2481, Accuracy=96.15%\n",
            "Epoch 11: Loss=1.0766, Accuracy=92.31%\n",
            "Epoch 12: Loss=0.8831, Accuracy=92.31%\n",
            "Epoch 13: Loss=0.8288, Accuracy=96.15%\n",
            "Epoch 14: Loss=0.8012, Accuracy=96.15%\n",
            "Epoch 15: Loss=0.6024, Accuracy=100.00%\n",
            "Epoch 16: Loss=0.5633, Accuracy=96.15%\n",
            "Epoch 17: Loss=0.5374, Accuracy=100.00%\n",
            "Epoch 18: Loss=0.6504, Accuracy=96.15%\n",
            "Epoch 19: Loss=0.3917, Accuracy=100.00%\n",
            "Epoch 20: Loss=0.3824, Accuracy=100.00%\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# 📘 Educational Lab: Mini GPT-3 (inspired by Brown et al., 2020)\n",
        "# ================================================================\n",
        "# This is a simplified demo for teaching purposes, not a full GPT-3.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 1. TOY DATASET (tiny corpus for demonstration)\n",
        "# ------------------------------------------------\n",
        "corpus = [\n",
        "    \"deep learning changes the world\",\n",
        "    \"transformers are powerful models\",\n",
        "    \"language models can generate text\",\n",
        "    \"artificial intelligence is important\",\n",
        "    \"machine learning enables predictions\",\n",
        "    \"unsupervised learning reduces labels\",\n",
        "    \"neural networks learn representations\",\n",
        "    \"attention mechanisms improve results\"\n",
        "]\n",
        "\n",
        "# Simple whitespace tokenization\n",
        "vocab = sorted(set(\" \".join(corpus).split()))\n",
        "stoi = {s:i+2 for i,s in enumerate(vocab)} # reserve 0:<PAD>, 1:<UNK>\n",
        "stoi[\"<PAD>\"] = 0\n",
        "stoi[\"<UNK>\"] = 1\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "vocab_size = len(stoi)\n",
        "\n",
        "def encode(sentence): return [stoi.get(w,1) for w in sentence.split()]\n",
        "def decode(indices): return \" \".join([itos[i] for i in indices if i>1])\n",
        "\n",
        "encoded_corpus = [encode(sent) for sent in corpus]\n",
        "\n",
        "# Dataset: context → next token\n",
        "class LMDataset(Dataset):\n",
        "    def __init__(self, sequences, context_len=6):\n",
        "        self.data = []\n",
        "        self.context_len = context_len\n",
        "        for seq in sequences:\n",
        "            for i in range(1, len(seq)):\n",
        "                context = seq[:i]\n",
        "                target = seq[i]\n",
        "                # pad/truncate\n",
        "                context = [0]*(context_len-len(context)) + context[-context_len:]\n",
        "                self.data.append((torch.tensor(context), torch.tensor(target)))\n",
        "    def __len__(self): return len(self.data)\n",
        "    def __getitem__(self, idx): return self.data[idx]\n",
        "\n",
        "dataset = LMDataset(encoded_corpus, context_len=6)\n",
        "loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 2. MINI GPT-3 MODEL (small Transformer decoder)\n",
        "# ------------------------------------------------\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(embed_dim, ff_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_dim, embed_dim)\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, x):\n",
        "        attn_output, _ = self.attn(x, x, x, need_weights=False)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.ff(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class MiniGPT3(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=64, num_heads=2, ff_dim=128, num_layers=2, context_len=6):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.pos_embed = nn.Embedding(context_len, embed_dim)\n",
        "        self.layers = nn.ModuleList([TransformerBlock(embed_dim, num_heads, ff_dim) for _ in range(num_layers)])\n",
        "        self.lm_head = nn.Linear(embed_dim, vocab_size)\n",
        "        self.context_len = context_len\n",
        "    def forward(self, x):\n",
        "        b,t = x.size()\n",
        "        pos = torch.arange(0,t).unsqueeze(0).to(x.device)\n",
        "        x = self.embed(x) + self.pos_embed(pos)\n",
        "        x = x.transpose(0,1)  # seq, batch, embed\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        x = x.transpose(0,1)  # batch, seq, embed\n",
        "        return self.lm_head(x)\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 3. TRAINING LOOP\n",
        "# ------------------------------------------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = MiniGPT3(vocab_size=vocab_size).to(device)\n",
        "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "losses, accs = [], []\n",
        "for epoch in range(20):\n",
        "    total_loss, correct, total = 0,0,0\n",
        "    for context, target in loader:\n",
        "        context, target = context.to(device), target.to(device)\n",
        "        logits = model(context)[:,-1,:]  # predict next token\n",
        "        loss = criterion(logits, target)\n",
        "        opt.zero_grad(); loss.backward(); opt.step()\n",
        "        total_loss += loss.item()\n",
        "        pred = torch.argmax(logits, dim=-1)\n",
        "        correct += (pred==target).sum().item()\n",
        "        total += target.size(0)\n",
        "    avg_loss = total_loss/len(loader)\n",
        "    acc = correct/total\n",
        "    losses.append(avg_loss); accs.append(acc)\n",
        "    print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, Accuracy={acc*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------\n",
        "# 4. VISUALIZATION (loss + accuracy curves)\n",
        "# ------------------------------------------------\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(losses, marker='o'); plt.title(\"Training Loss\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(accs, marker='s'); plt.title(\"Training Accuracy\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "xSoWMGs5UnTh",
        "outputId": "9168369e-1df7-420d-d89b-9a57f27d5e30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------\n",
        "# 5. TEXT GENERATION (Zero-/Few-shot)\n",
        "# ------------------------------------------------\n",
        "def generate_text(prompt, max_len=8):\n",
        "    model.eval()\n",
        "    tokens = encode(prompt)\n",
        "    tokens = [0]*(model.context_len - len(tokens)) + tokens[-model.context_len:]\n",
        "    generated = tokens.copy()\n",
        "    for _ in range(max_len):\n",
        "        inp = torch.tensor([generated[-model.context_len:]]).to(device)\n",
        "        logits = model(inp)[:,-1,:]\n",
        "        next_token = torch.argmax(logits, dim=-1).item()\n",
        "        generated.append(next_token)\n",
        "    return decode(generated)\n",
        "\n",
        "print(\"\\n=== Sample Generations ===\")\n",
        "print(\"Zero-shot Prompt: 'deep learning' →\", generate_text(\"deep learning\"))\n",
        "print(\"Few-shot Prompt: 'machine learning enables' →\", generate_text(\"machine learning enables\"))\n",
        "print(\"Few-shot Prompt: 'language models can' →\", generate_text(\"language models can\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CzvAoecUu1N",
        "outputId": "9264900d-f547-4c10-8c8a-376a2278b2f2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Sample Generations ===\n",
            "Zero-shot Prompt: 'deep learning' → deep learning changes the world representations models can generate text\n",
            "Few-shot Prompt: 'machine learning enables' → machine learning enables predictions enables predictions text models can generate text\n",
            "Few-shot Prompt: 'language models can' → language models can generate text models can generate text models can\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpretation of Results\n",
        "\n",
        "## Reported Metrics\n",
        "- **Initial training loss (Epoch 1):** 3.6912  \n",
        "- **Final training loss (Epoch 20):** 0.3824  \n",
        "- **Loss reduction:** ≈ 90% decrease across 20 epochs  \n",
        "- **Initial accuracy (Epoch 1):** 3.85% (near random guessing given vocabulary size)  \n",
        "- **Final accuracy (Epoch 20):** 100%  \n",
        "\n",
        "**Training curves:**\n",
        "- Loss decreases smoothly and monotonically.  \n",
        "- Accuracy rises rapidly from ~25% (Epochs 2–3) to >90% by Epoch 11.  \n",
        "- Plateau reached near 100% after Epoch 12–15.  \n",
        "\n",
        "---\n",
        "\n",
        "## Interpretation in Context\n",
        "\n",
        "### Convergence and Learning Dynamics\n",
        "- The model exhibits **stable convergence**, with consistent reduction in cross-entropy loss.  \n",
        "- The steep accuracy gains in the first 10 epochs indicate **rapid acquisition of core token–context dependencies** within the toy corpus.  \n",
        "- Plateauing of both loss and accuracy after ~Epoch 12 shows the model has effectively **memorized the dataset**.  \n",
        "\n",
        "### Generalization and Overfitting\n",
        "- Achieving **100% training accuracy** suggests **overfitting**: the model’s capacity exceeded dataset complexity.  \n",
        "- On such a small corpus, this reflects memorization rather than robust generalization.  \n",
        "- In contrast, large-scale models like GPT-3 achieve sustained generalization by training on **diverse, high-volume corpora**.  \n",
        "\n",
        "---\n",
        "\n",
        "## Generated Text Samples\n",
        "\n",
        "- **Zero-shot prompt (“deep learning”):**  \n",
        "  Output coherent at first (*“deep learning changes the world representations models can generate text”*), but quickly devolves into redundancy.  \n",
        "\n",
        "- **Few-shot prompt (“machine learning enables”):**  \n",
        "  Local coherence preserved (*“predictions enables predictions”*), but with **repetition loops**.  \n",
        "\n",
        "- **Few-shot prompt (“language models can”):**  \n",
        "  Degeneracy problem emerges (*“language models can generate text models can generate text”*), reflecting limitations in long-range novelty.  \n",
        "\n",
        "**Observation:** Generation samples illustrate both **basic coherence** and the **degeneracy/repetition issue** characteristic of early-scale autoregressive models.  \n",
        "\n",
        "---\n",
        "\n",
        "## Statistical Significance\n",
        "- The ~90% reduction in training loss implies a **large exponential reduction in perplexity**, signifying improved certainty in predictions.  \n",
        "- Accuracy gains provide **categorical confirmation** that the model learned token–context dependencies within the dataset.  \n",
        "- These metrics validate the model’s ability to optimize next-token prediction under the GPT training framework.  \n",
        "\n",
        "---\n",
        "\n",
        "## Implications\n",
        "1. **Educational Value:** Demonstrates the **core GPT principle**: autoregressive Transformers learn to predict next tokens effectively and adapt in-context from prompts.  \n",
        "2. **Limitations of Scale:** With a small corpus, results reflect **memorization** and **low generative diversity**, underscoring the necessity of massive corpora for true few-shot generalization.  \n",
        "3. **Alignment with GPT-3 Findings:** Despite scale limits, the toy model shows **prompt-based generation capability**. This mirrors GPT-3’s paradigm of **zero-/few-shot learning via conditional inference**.  \n",
        "\n",
        "---\n",
        "\n",
        "## Conclusion\n",
        "The experiment demonstrates that even a small-scale GPT-style model can:  \n",
        "- Achieve near-perfect loss reduction and accuracy on a toy dataset.  \n",
        "- Converge stably and predict tokens reliably.  \n",
        "- Generate coherent continuations but suffer from **repetition and shallow semantics** due to scale limitations.  \n",
        "\n",
        "**Overall:** The results provide a didactic miniature version of the findings in **Brown et al. (2020)**—showing how scaling transforms memorization into **general-purpose few-shot learning** when applied to massive datasets and architectures.\n"
      ],
      "metadata": {
        "id": "5EaICQRfVTz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Table: Related Work References in *Language Models are Few-Shot Learners* (Brown et al., 2020)\n",
        "\n",
        "| **Author(s)** | **Year** | **Title** | **Venue** | **Connection to This Paper** |\n",
        "|---------------|----------|-----------|-----------|-------------------------------|\n",
        "| Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I. | 2017 | *Attention Is All You Need* | NeurIPS | Introduced the Transformer architecture, which underpins GPT-3’s autoregressive decoder design. |\n",
        "| Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. | 2018 | *Improving Language Understanding by Generative Pre-Training* | OpenAI Technical Report | Proposed GPT-1, demonstrating generative pretraining with fine-tuning for NLP tasks; a direct precursor to GPT-3. |\n",
        "| Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. | 2019 | *Language Models are Unsupervised Multitask Learners* | OpenAI Technical Report | Introduced GPT-2, showing that scaling improves zero-shot performance; GPT-3 extends this scaling by two orders of magnitude. |\n",
        "| Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. | 2019 | *BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding* | NAACL | Demonstrated the effectiveness of masked language modeling and large-scale pretraining; contrasts with GPT-3’s autoregressive training. |\n",
        "| Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., & Liu, P. J. | 2020 | *Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (T5)* | JMLR | Showed that large-scale text-to-text pretraining achieves SOTA across tasks; GPT-3 compares favorably without task-specific fine-tuning. |\n",
        "| Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q. V., & Salakhutdinov, R. | 2019 | *Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context* | ACL | Extended Transformer context length; related to GPT-3’s handling of larger contexts during pretraining. |\n",
        "| Yang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R., & Le, Q. V. | 2019 | *XLNet: Generalized Autoregressive Pretraining for Language Understanding* | NeurIPS | Combined autoregressive and permutation-based objectives; GPT-3 builds upon autoregressive-only scaling. |\n",
        "| Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., … & Stoyanov, V. | 2019 | *RoBERTa: A Robustly Optimized BERT Pretraining Approach* | arXiv | Enhanced BERT pretraining with more data and longer training; informs scaling comparisons with GPT-3. |\n",
        "| Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., … & Amodei, D. | 2020 | *Scaling Laws for Neural Language Models* | arXiv | Provided empirical scaling laws showing that performance improves predictably with model size, dataset size, and compute; forms the theoretical basis for GPT-3’s extreme scaling. |\n",
        "\n",
        "---\n",
        "\n",
        " This table highlights the **key works GPT-3 builds upon or contrasts with**—particularly around:\n",
        "- **Transformer architecture** (Vaswani et al., 2017)  \n",
        "- **Generative pretraining (GPT-1, GPT-2)**  \n",
        "- **Alternative pretraining methods (BERT, XLNet, RoBERTa, T5)**  \n",
        "- **Scaling theory (Kaplan et al., 2020)**  \n",
        "\n",
        "Together, these works situate GPT-3 as the culmination of **scaling autoregressive Transformers** into a universal few-shot learner.\n"
      ],
      "metadata": {
        "id": "F7urW0JrWFdD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparative Table of Related Works in GPT-3 Context\n",
        "\n",
        "| **Paper Title** | **Authors** | **Year** | **Main Problem Addressed** | **Proposed Solution** | **Methodology** | **Key Results** | **Contributions** |\n",
        "|-----------------|-------------|----------|----------------------------|-----------------------|-----------------|-----------------|-------------------|\n",
        "| *Attention Is All You Need* | Vaswani et al. | 2017 | RNN/CNN limitations in sequence modeling (long dependencies, inefficiency). | Introduced Transformer architecture with self-attention. | Encoder-decoder Transformer using scaled dot-product attention. | Achieved SOTA in machine translation with faster training and better scalability. | Established the Transformer as the foundation of modern NLP, enabling GPT models. |\n",
        "| *Improving Language Understanding by Generative Pre-Training (GPT-1)* | Radford et al. | 2018 | Lack of general pretraining methods for NLP tasks. | Generative pretraining on unlabeled data, followed by supervised fine-tuning. | Pretrained Transformer LM on BooksCorpus, fine-tuned on downstream tasks. | Improved performance across classification and QA tasks with less labeled data. | First demonstration of generative pretraining as a general-purpose NLP strategy. |\n",
        "| *Language Models are Unsupervised Multitask Learners (GPT-2)* | Radford et al. | 2019 | Limited zero-shot generalization in pretrained models. | Scale up language models and test zero-shot performance. | 1.5B parameter Transformer trained on WebText; evaluated on NLP benchmarks without fine-tuning. | Strong zero-shot performance, rivaling supervised models in some tasks. | Proved that larger LMs act as multitask learners without explicit fine-tuning. |\n",
        "| *BERT: Pre-training of Deep Bidirectional Transformers* | Devlin et al. | 2019 | Shallow contextual embeddings limited transfer. | Masked LM and next-sentence prediction for deep bidirectional pretraining. | Large Transformer encoder trained on BooksCorpus + Wikipedia. | SOTA across GLUE, SQuAD, and other benchmarks. | Established bidirectional pretraining as dominant paradigm; inspired robust fine-tuning approaches. |\n",
        "| *Exploring the Limits of Transfer Learning with T5* | Raffel et al. | 2020 | Fragmented task formulations hindered transfer. | Unified text-to-text framework for all NLP tasks. | Pretrained large encoder-decoder Transformers on C4 dataset. | Achieved SOTA on SuperGLUE and multiple tasks. | Demonstrated effectiveness of a unified text-to-text paradigm for transfer learning. |\n",
        "| *Transformer-XL* | Dai et al. | 2019 | Fixed-length context in Transformers limited long-term dependencies. | Introduced recurrence to extend context length. | Modified Transformer with segment-level recurrence. | Outperformed baselines in language modeling (WikiText-103). | Enabled modeling of longer contexts, improving LM performance. |\n",
        "| *XLNet* | Yang et al. | 2019 | Limitations of BERT’s masked LM objective (independence assumptions). | Generalized autoregressive pretraining with permutation-based factorization. | Permutation LM objective on large Transformer. | Outperformed BERT on GLUE, SQuAD, RACE. | Combined benefits of autoregression and bidirectionality. |\n",
        "| *RoBERTa* | Liu et al. | 2019 | Suboptimal BERT training protocol. | Robust optimization with larger data, longer training, dynamic masking. | Large-scale retraining of BERT with modifications. | Outperformed BERT across NLP benchmarks. | Highlighted importance of training regime and scale in performance. |\n",
        "| *Scaling Laws for Neural Language Models* | Kaplan et al. | 2020 | Lack of systematic understanding of how model size, data, and compute affect performance. | Empirical scaling laws showing predictable improvements. | Analyzed performance scaling across models up to billions of parameters. | Demonstrated log-linear scaling with size; diminishing returns only at limits. | Provided theoretical foundation for scaling GPT-3 to 175B parameters. |\n",
        "\n",
        "---\n",
        "\n",
        "## Synthesis\n",
        "\n",
        "- **GPT-1 → GPT-2 → GPT-3:** Progressive scaling demonstrated that *generative pretraining alone* yields strong generalization.  \n",
        "- **BERT / RoBERTa / XLNet / T5:** Parallel innovations emphasized bidirectionality, robustness, and unified task frameworks.  \n",
        "- **Transformer-XL & Scaling Laws:** Addressed context length and provided the *theoretical justification for scaling*, both critical to GPT-3’s design.  \n",
        "\n",
        "Together, these works form the intellectual and methodological foundation that positioned GPT-3 as the first **general-purpose few-shot learner** at scale.\n"
      ],
      "metadata": {
        "id": "Sl3JBOfWWskW"
      }
    }
  ]
}