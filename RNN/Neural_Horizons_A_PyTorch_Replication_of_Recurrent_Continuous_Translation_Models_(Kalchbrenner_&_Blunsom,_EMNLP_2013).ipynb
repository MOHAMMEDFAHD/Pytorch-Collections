{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìñ Academic Summary: *Recurrent Continuous Translation Models*  \n",
        "*Kalchbrenner & Blunsom, EMNLP 2013*\n",
        "\n",
        "# https://aclanthology.org/D13-1176.pdf\n",
        "\n",
        "---\n",
        "\n",
        "## **Abstract**\n",
        "The authors introduce **Recurrent Continuous Translation Models (RCTMs)**, a new family of machine translation models that operate entirely on **continuous vector representations** of words, phrases, and sentences.  \n",
        "Unlike phrase-based SMT, RCTMs **remove explicit alignments** and **phrasal translation units**, combining:  \n",
        "- a **Recurrent Language Model (RLM)** for target-side generation,  \n",
        "- a **Convolutional Sentence Model (CSM)** for source conditioning.  \n",
        "\n",
        "Key results:  \n",
        "- **43% lower perplexity** vs. alignment-based SMT baselines,  \n",
        "- sensitivity to **syntax and semantics** despite no alignments,  \n",
        "- competitive performance when used for **n-best list rescoring**.\n",
        "\n",
        "---\n",
        "\n",
        "## **Problem**\n",
        "Traditional phrase-based SMT suffers from:  \n",
        "- **Alignment dependency** ‚Üí requires explicit word/phrase alignments.  \n",
        "- **Data sparsity** ‚Üí rare/unseen phrases poorly estimated.  \n",
        "- **Rigid phrase tables** ‚Üí weak generalization across morphologically or semantically related structures.  \n",
        "\n",
        "üëâ These limitations hinder **generalization, handling of rare events, and semantic fidelity**.\n",
        "\n",
        "---\n",
        "\n",
        "## **Purposes**\n",
        "The paper aims to:  \n",
        "1. Develop a **purely continuous representation framework** for translation.  \n",
        "2. Build models **sensitive to word order, syntax, and meaning** without alignments.  \n",
        "3. Evaluate whether RCTMs can compete with **state-of-the-art phrase/alignment-based SMT** systems.\n",
        "\n",
        "---\n",
        "\n",
        "## **Methodology**\n",
        "Two RCTM architectures are proposed:  \n",
        "\n",
        "### **RCTM I**  \n",
        "- Encodes the full source sentence via a **Convolutional Sentence Model (CSM)** ‚Üí continuous vector.  \n",
        "- Target **RLM** is conditioned on this vector to generate words sequentially.  \n",
        "\n",
        "### **RCTM II**  \n",
        "- Uses **Convolutional n-gram Models (CGM)** for intermediate representations.  \n",
        "- Transforms source n-grams into target-side conditioning vectors.  \n",
        "- Conditions the **RLM word-by-word** + explicit **sentence length modeling**.  \n",
        "\n",
        "**Training Setup**  \n",
        "- **Corpus:** English‚ÄìFrench WMT 2013 (news commentary, ~145k pairs).  \n",
        "- **Objective:** Cross-entropy loss with **BPTT + Adagrad** optimization.  \n",
        "- **Evaluation Metrics:** perplexity, sensitivity tests, qualitative generation, BLEU for rescoring.\n",
        "\n",
        "---\n",
        "\n",
        "## **Results**\n",
        "- **Perplexity:**  \n",
        "  - RCTM II ‚Üí **43% lower perplexity** vs. IBM alignment-based models.  \n",
        "  - Also ~40% lower than RCTM I.  \n",
        "\n",
        "- **Sensitivity to Structure:**  \n",
        "  - Random word order in source sentence sharply increased perplexity.  \n",
        "  - Confirms RCTMs capture **syntax and order dependencies**.  \n",
        "\n",
        "- **Qualitative Translations:**  \n",
        "  - Outputs preserve **morphological, syntactic, semantic fidelity** (plural forms, tense, negation).  \n",
        "\n",
        "- **Rescoring n-best lists:**  \n",
        "  - With a word penalty feature, RCTMs **matched cdec** (a strong SMT system using 12 engineered features).  \n",
        "\n",
        "---\n",
        "\n",
        "## **Conclusions**\n",
        "- **RCTMs** establish a new paradigm: translation via **joint continuous representations** (no alignments/phrase tables).  \n",
        "- Achieve:  \n",
        "  - Lower perplexity,  \n",
        "  - Strong syntactic-semantic sensitivity,  \n",
        "  - Competitive BLEU.  \n",
        "- Open doors to:  \n",
        "  - **Morphologically rich languages**,  \n",
        "  - **Discourse-level modeling**,  \n",
        "  - **Multilingual scaling**.  \n",
        "\n",
        "üöÄ **Historical Significance**:  \n",
        "RCTMs represent a **transitional milestone** from phrase-based SMT to **end-to-end neural MT**‚Äîa precursor to **attention-based seq2seq** and, ultimately, the **Transformer architecture**.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "LKZLFXnFpduN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìê Mathematical & Statistical Equations in RCTM (Kalchbrenner & Blunsom, 2013)\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Translation Probability Factorization\n",
        "For a source sentence $e = e_1, \\dots, e_k$ and a target sentence $f = f_1, \\dots, f_m$:  \n",
        "\n",
        "$$\n",
        "P(f \\mid e) = \\prod_{i=1}^m P(f_i \\mid f_{1:i-1}, e) \\tag{1}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Recurrent Language Model (RLM)\n",
        "For a target sequence $f = f_1, \\dots, f_m$:  \n",
        "\n",
        "$$\n",
        "P(f) = \\prod_{i=1}^m P(f_i \\mid f_{1:i-1}) \\tag{2}\n",
        "$$\n",
        "\n",
        "Hidden state recursion:  \n",
        "\n",
        "$$\n",
        "h_1 = \\sigma(I \\cdot v(f_1)) \\tag{3a}\n",
        "$$\n",
        "\n",
        "$$\n",
        "h_{i+1} = \\sigma(R \\cdot h_i + I \\cdot v(f_{i+1})) \\tag{3b}\n",
        "$$\n",
        "\n",
        "$$\n",
        "o_{i+1} = O \\cdot h_i \\tag{3c}\n",
        "$$\n",
        "\n",
        "Softmax output distribution:  \n",
        "\n",
        "$$\n",
        "P(f_i = v \\mid f_{1:i-1}) =\n",
        "\\frac{\\exp(o_{i,v})}{\\sum_{v=1}^{|V|} \\exp(o_{i,v})} \\tag{4}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Convolutional Sentence Model (CSM)\n",
        "Sentence matrix representation:  \n",
        "\n",
        "$$\n",
        "E_{:,i}^e = v(e_i) \\tag{5}\n",
        "$$\n",
        "\n",
        "One-dimensional convolution:  \n",
        "\n",
        "$$\n",
        "(K_i \\ast M)_{:,a} =\n",
        "K_{i,:,1} \\odot M_{:,a} +\n",
        "K_{i,:,2} \\odot M_{:,a+1} +\n",
        "K_{i,:,3} \\odot M_{:,a+2} \\tag{6}\n",
        "$$\n",
        "\n",
        "Recursive convolution:  \n",
        "\n",
        "$$\n",
        "E_1^e = E^e \\tag{7a}\n",
        "$$\n",
        "\n",
        "$$\n",
        "E_{i+1}^e = \\sigma(K_{i+1} \\ast E_i^e) \\tag{7b}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## 4. RCTM I (Sentence-Level Conditioning)\n",
        "Source-conditioned hidden states:  \n",
        "\n",
        "$$\n",
        "s = S \\cdot csm(e) \\tag{8a}\n",
        "$$\n",
        "\n",
        "$$\n",
        "h_1 = \\sigma(I \\cdot v(f_1) + s) \\tag{8b}\n",
        "$$\n",
        "\n",
        "$$\n",
        "h_{i+1} = \\sigma(R \\cdot h_i + I \\cdot v(f_{i+1}) + s) \\tag{8c}\n",
        "$$\n",
        "\n",
        "$$\n",
        "o_{i+1} = O \\cdot h_i \\tag{8d}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## 5. RCTM II (n-gram Conditioning)\n",
        "Translation probability with explicit length modeling:  \n",
        "\n",
        "$$\n",
        "P(f \\mid e) = P(f \\mid m, e) \\cdot P(m \\mid e) \\tag{9a}\n",
        "$$\n",
        "\n",
        "$$\n",
        "P(f \\mid e) = \\prod_{i=1}^m P(f_{i+1} \\mid f_{1:i}, m, e) \\cdot P(m \\mid e) \\tag{9b}\n",
        "$$\n",
        "\n",
        "CGM conditioning and inverse reconstruction:  \n",
        "\n",
        "$$\n",
        "E_g = cgm(e,4) \\tag{10a}\n",
        "$$\n",
        "\n",
        "$$\n",
        "F_{:,j} = \\sigma(T \\cdot E_{g,:,j}) \\tag{10b}\n",
        "$$\n",
        "\n",
        "$$\n",
        "F = icgm(F_g, m) \\tag{10c}\n",
        "$$\n",
        "\n",
        "Hidden state updates:  \n",
        "\n",
        "$$\n",
        "h_1 = \\sigma(I \\cdot v(f_1) + S \\cdot F_{:,1}) \\tag{10d}\n",
        "$$\n",
        "\n",
        "$$\n",
        "h_{i+1} = \\sigma(R \\cdot h_i + I \\cdot v(f_{i+1}) + S \\cdot F_{:,i+1}) \\tag{10e}\n",
        "$$\n",
        "\n",
        "$$\n",
        "o_{i+1} = O \\cdot h_i \\tag{10f}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Target Sentence Length Distribution\n",
        "Modeled as a **Poisson process**:  \n",
        "\n",
        "$$\n",
        "P(m \\mid e) = P(m \\mid k) = \\text{Poisson}(\\lambda_k) \\tag{11}\n",
        "$$\n",
        "\n",
        "where $k$ is the source sentence length.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Summary\n",
        "- **Eq. (1‚Äì2):** Sentence probability factorization.  \n",
        "- **Eq. (3‚Äì4):** RLM hidden state dynamics & softmax prediction.  \n",
        "- **Eq. (5‚Äì7):** Convolutional Sentence Model for source encoding.  \n",
        "- **Eq. (8):** RCTM I (sentence-level conditioning).  \n",
        "- **Eq. (9‚Äì10):** RCTM II (n-gram + inverse CGM conditioning).  \n",
        "- **Eq. (11):** Poisson-based target length modeling.  \n"
      ],
      "metadata": {
        "id": "Hqnb6Q8IrfUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìñ Role of Convolutions in RCTM (Kalchbrenner & Blunsom, 2013)\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ 1. Purpose of Convolutions\n",
        "- Traditional **SMT** relied on phrase tables + explicit alignments.  \n",
        "- RCTM introduced **continuous sentence representations** to overcome sparsity and rigid phrase units.  \n",
        "- Convolutions were used to:  \n",
        "  - Extract **local n-gram features**.  \n",
        "  - Compose them **hierarchically** into sentence-level embeddings.  \n",
        "- Thus, the CNN served as a **sentence encoder** for the source.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ 2. Convolutional Sentence Model (CSM) ‚Äî *RCTM I*\n",
        "- Each source word ‚Üí embedding vector.  \n",
        "- Sentence matrix:  \n",
        "  $$\n",
        "  E^e_{:,i} = v(e_i)\n",
        "  $$\n",
        "- Apply **1D convolution** across word windows (sliding n-grams):  \n",
        "  $$\n",
        "  (K_i \\ast M)_{:,a} =\n",
        "  K_{i,:,1} \\odot M_{:,a} +\n",
        "  K_{i,:,2} \\odot M_{:,a+1} +\n",
        "  K_{i,:,3} \\odot M_{:,a+2}\n",
        "  $$\n",
        "- Repeated convolution layers compress sentence ‚Üí **fixed-length vector**.  \n",
        "- This vector conditions the **RNN decoder (Recurrent Language Model)**.  \n",
        "\n",
        "üëâ *CSM encodes the entire source into a single global embedding.*\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ 3. Convolutional n-gram Model (CGM) ‚Äî *RCTM II*\n",
        "- Instead of one global vector, RCTM II builds **localized embeddings** for n-grams.  \n",
        "- These features are injected **step-by-step** into the decoder:  \n",
        "  $$\n",
        "  h_{i+1} = \\sigma(R \\cdot h_i + I \\cdot v(f_{i+1}) + S \\cdot F_{:,i+1})\n",
        "  $$\n",
        "  - $F_{:,i+1}$ = projected **n-gram feature** for timestep $i+1$.  \n",
        "- Introduced **inverse CGM (icgm)** to match source/target lengths.  \n",
        "\n",
        "üëâ *CGM provides dynamic, time-varying local features ‚Äî closer to later attention ideas.*\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ 4. Deployment in the Translation Pipeline\n",
        "- **Encoder (CNN):** extracts semantic‚Äìsyntactic features (global or local).  \n",
        "- **Decoder (RNN):** generates target sequence word-by-word.  \n",
        "- Integration:  \n",
        "  - **RCTM I:** global CNN vector added at every decoding step.  \n",
        "  - **RCTM II:** step-specific CNN n-gram features fed into the decoder.  \n",
        "\n",
        "---\n",
        "\n",
        "## üìë Academic Framing\n",
        "- Unlike vision tasks (classification), here **convolutions compose linguistic features**:  \n",
        "  - **CSM:** hierarchical sentence embeddings.  \n",
        "  - **CGM:** local n-gram embeddings aligned to decoding steps.  \n",
        "- This design foreshadowed encoder‚Äìdecoder architectures:  \n",
        "  - **CNN encoders** ‚Üí source representation.  \n",
        "  - **RNN decoders** ‚Üí target generation.  \n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ In Essence\n",
        "Kalchbrenner & Blunsom (2013) used **convolutions to transform variable-length source text into continuous, structured representations**.  \n",
        "- **RCTM I:** one global representation.  \n",
        "- **RCTM II:** dynamic local features.  \n",
        "\n",
        "This was an **early bridge** from SMT toward neural MT, paving the way for Seq2Seq (2014) and Attention (2015).\n"
      ],
      "metadata": {
        "id": "XUC7UPtp3F1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# üìò Recurrent Continuous Translation Models (RCTM) in PyTorch\n",
        "# Inspired by Kalchbrenner & Blunsom (EMNLP 2013)\n",
        "# ============================================================\n",
        "\n",
        "# --- 1. Imports ---\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "f7D-8jt738yw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Toy Dataset (English‚ÜíFrench mini parallel corpus) ---\n",
        "# In practice, use WMT data; here we use a toy set for demonstration.\n",
        "pairs = [\n",
        "    (\"i am a student\", \"je suis un etudiant\"),\n",
        "    (\"he is a teacher\", \"il est un professeur\"),\n",
        "    (\"she is a doctor\", \"elle est une docteure\"),\n",
        "    (\"they are happy\", \"ils sont heureux\"),\n",
        "    (\"we are friends\", \"nous sommes amis\")\n",
        "]"
      ],
      "metadata": {
        "id": "4rKhBIXD3_eC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build simple vocabularies\n",
        "def build_vocab(sentences):\n",
        "    vocab = {\"<pad>\":0,\"<sos>\":1,\"<eos>\":2,\"<unk>\":3}\n",
        "    for s in sentences:\n",
        "        for w in s.split():\n",
        "            if w not in vocab:\n",
        "                vocab[w] = len(vocab)\n",
        "    return vocab\n",
        "\n",
        "src_vocab = build_vocab([p[0] for p in pairs])\n",
        "tgt_vocab = build_vocab([p[1] for p in pairs])\n",
        "inv_tgt_vocab = {i:w for w,i in tgt_vocab.items()}"
      ],
      "metadata": {
        "id": "5hxl-gXV4C1F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode sentences into index tensors\n",
        "def encode(sentence, vocab, max_len=8):\n",
        "    tokens = [vocab.get(w, vocab[\"<unk>\"]) for w in sentence.split()]\n",
        "    tokens = [vocab[\"<sos>\"]] + tokens + [vocab[\"<eos>\"]]\n",
        "    tokens += [vocab[\"<pad>\"]] * (max_len - len(tokens))\n",
        "    return torch.tensor(tokens[:max_len])\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, pairs):\n",
        "        self.data = [(encode(src, src_vocab), encode(tgt, tgt_vocab)) for src,tgt in pairs]\n",
        "    def __len__(self): return len(self.data)\n",
        "    def __getitem__(self, idx): return self.data[idx]\n",
        "\n",
        "dataset = TranslationDataset(pairs)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "SHOiMZyJ4HR8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Core Models ---\n",
        "# üîπ Recurrent Language Model (for target generation)\n",
        "class RLM(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = self.embed(x)\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        logits = self.fc(out)\n",
        "        return logits, hidden\n",
        "\n",
        "# üîπ Convolutional Sentence Model (for source encoding)\n",
        "class CSM(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, kernel_sizes=[2,3]):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "        self.convs = nn.ModuleList([nn.Conv1d(embed_size, hidden_size, k) for k in kernel_sizes])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x).transpose(1,2)\n",
        "        conv_outs = [torch.max(F.relu(conv(x)), dim=2)[0] for conv in self.convs]\n",
        "        return torch.cat(conv_outs, dim=1)  # sentence vector\n",
        "\n",
        "# üîπ RCTM I: RLM conditioned on CSM sentence vector\n",
        "class RCTM1(nn.Module):\n",
        "    def __init__(self, src_vocab, tgt_vocab, embed_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.csm = CSM(src_vocab, embed_size, hidden_size)\n",
        "        self.rlm = RLM(tgt_vocab, embed_size, hidden_size)\n",
        "\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_repr = self.csm(src)  # (batch, hidden*len(kernels))\n",
        "        logits, _ = self.rlm(tgt)\n",
        "        # condition RLM outputs by adding src_repr\n",
        "        conditioned = logits + src_repr.unsqueeze(1)\n",
        "        return conditioned\n",
        "\n",
        "# üîπ Convolutional n-gram Model (CGM) for RCTM II\n",
        "class CGM(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, n=3):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "        # padding = n//2 keeps sequence length same (like ‚Äúsame‚Äù padding in CNNs)\n",
        "        self.conv = nn.Conv1d(embed_size, hidden_size, n, padding=n//2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x).transpose(1,2)   # (batch, embed, seq_len)\n",
        "        out = F.relu(self.conv(x)).transpose(1,2)  # (batch, seq_len, hidden)\n",
        "        return out\n",
        "\n",
        "\n",
        "# üîπ RCTM II: RLM conditioned on CGM (local n-grams)\n",
        "class RCTM2(nn.Module):\n",
        "    def __init__(self, src_vocab, tgt_vocab, embed_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.cgm = CGM(src_vocab, embed_size, hidden_size)\n",
        "        self.rlm = RLM(tgt_vocab, embed_size, hidden_size)\n",
        "        self.proj = nn.Linear(hidden_size, tgt_vocab)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        ngram_repr = self.cgm(src)                       # (batch, src_len, hidden)\n",
        "        logits, _ = self.rlm(tgt)                        # (batch, tgt_len, vocab_size)\n",
        "        ngram_repr = ngram_repr[:, :logits.size(1), :]   # trim/pad to tgt_len\n",
        "        ngram_proj = self.proj(ngram_repr)               # (batch, tgt_len, vocab_size)\n",
        "        conditioned = logits + ngram_proj                # aligned addition\n",
        "        return conditioned"
      ],
      "metadata": {
        "id": "H-4VMbg34NVd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Training Function ---\n",
        "def train_model(model, dataloader, epochs=20):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab[\"<pad>\"])\n",
        "    train_losses = []\n",
        "    for epoch in range(epochs):\n",
        "        model.train(); total_loss = 0\n",
        "        for src, tgt in dataloader:\n",
        "            tgt_in, tgt_out = tgt[:,:-1], tgt[:,1:]  # shift for teacher forcing\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(src, tgt_in)\n",
        "            loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss/len(dataloader)\n",
        "        train_losses.append(avg_loss)\n",
        "        print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, PPL={torch.exp(torch.tensor(avg_loss)):.2f}\")\n",
        "    return train_losses\n"
      ],
      "metadata": {
        "id": "8dugEx3j6RoF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Simple Prediction (greedy decoding) ---\n",
        "def translate(model, src_sentence, max_len=8):\n",
        "    model.eval()\n",
        "    src = encode(src_sentence, src_vocab).unsqueeze(0)\n",
        "    tgt = torch.tensor([[tgt_vocab[\"<sos>\"]]])\n",
        "    outputs = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_len):\n",
        "            logits = model(src, tgt)\n",
        "            next_word = logits[:,-1,:].argmax(1).item()\n",
        "            if next_word == tgt_vocab[\"<eos>\"]: break\n",
        "            outputs.append(inv_tgt_vocab.get(next_word,\"<unk>\"))\n",
        "            tgt = torch.cat([tgt, torch.tensor([[next_word]])], dim=1)\n",
        "    return \" \".join(outputs)"
      ],
      "metadata": {
        "id": "aPIEP2nc6VpE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Train + Evaluate + Visualize ---\n",
        "model = RCTM2(len(src_vocab), len(tgt_vocab), embed_size=32, hidden_size=32)  # choose RCTM1 or RCTM2\n",
        "losses = train_model(model, dataloader, epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e8KRJY06ZMm",
        "outputId": "1710f67d-2893-4e3c-e0fd-6865daa3a4fb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss=3.0039, PPL=20.16\n",
            "Epoch 2: Loss=1.9566, PPL=7.08\n",
            "Epoch 3: Loss=1.2039, PPL=3.33\n",
            "Epoch 4: Loss=0.7382, PPL=2.09\n",
            "Epoch 5: Loss=0.3884, PPL=1.47\n",
            "Epoch 6: Loss=0.2219, PPL=1.25\n",
            "Epoch 7: Loss=0.0993, PPL=1.10\n",
            "Epoch 8: Loss=0.0512, PPL=1.05\n",
            "Epoch 9: Loss=0.0264, PPL=1.03\n",
            "Epoch 10: Loss=0.0134, PPL=1.01\n",
            "Epoch 11: Loss=0.0089, PPL=1.01\n",
            "Epoch 12: Loss=0.0052, PPL=1.01\n",
            "Epoch 13: Loss=0.0040, PPL=1.00\n",
            "Epoch 14: Loss=0.0030, PPL=1.00\n",
            "Epoch 15: Loss=0.0021, PPL=1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss curve\n",
        "plt.plot(losses); plt.title(\"Training Loss\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Jsj8cadX6eKz",
        "outputId": "d6e5b9bd-ee2e-43d5-f05b-b941a417842f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LnZiGbipNgB",
        "outputId": "6e79af50-0aa3-4349-e289-fd836a651ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: je suis un etudiant\n",
            "Prediction: il est un professeur\n"
          ]
        }
      ],
      "source": [
        "# Test prediction\n",
        "print(\"Prediction:\", translate(model, \"i am a student\"))\n",
        "print(\"Prediction:\", translate(model, \"he is a teacher\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìñ Academic Interpretation of Results (Replication of RCTM2)\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Training Dynamics\n",
        "- **Loss trajectory:** 3.0039 ‚Üí 0.0021 (epoch 1 ‚Üí 15).  \n",
        "- **Perplexity (PPL):** 20.16 ‚Üí 1.0.  \n",
        "- **Interpretation:**  \n",
        "  - Monotonic decline without oscillations = **stable optimization** (Adam + gradient clipping).  \n",
        "  - The model quickly captured statistical regularities of the toy parallel corpus.  \n",
        "  - PPL ‚âà 1 implies near-perfect prediction of training targets.  \n",
        "\n",
        "---\n",
        "\n",
        "## 2. Generalization to Test Sentences\n",
        "- **Examples:**  \n",
        "  - *‚Äúi am a student‚Äù* ‚Üí *‚Äúje suis un etudiant‚Äù*  \n",
        "  - *‚Äúhe is a teacher‚Äù* ‚Üí *‚Äúil est un professeur‚Äù*  \n",
        "- **Observation:**  \n",
        "  - Outputs are **grammatically correct** (subject‚Äìverb agreement preserved).  \n",
        "  - Semantic roles and meanings map correctly across languages.  \n",
        "  - Confirms that RCTM2 transferred **morphological, syntactic, and semantic** information effectively‚Äîconsistent with Kalchbrenner & Blunsom (2013).  \n",
        "\n",
        "---\n",
        "\n",
        "## 3. Significance of Perplexity Reduction\n",
        "- **Meaning of PPL:** measures model‚Äôs confidence in predicting the correct target word given the source.  \n",
        "- **PPL ‚âà 1.0:**  \n",
        "  - Model assigns nearly all probability mass to the correct token at every step.  \n",
        "  - Typical on **tiny toy datasets**, but demonstrates expressive power of continuous sentence/phrase representations.  \n",
        "- Contrasts with **count-based SMT**, which struggles with sparsity and rare events.  \n",
        "\n",
        "---\n",
        "\n",
        "## 4. Limitations\n",
        "- **Tiny dataset** (5 parallel pairs): model essentially **memorized** translations (overfitting).  \n",
        "- On realistic corpora (e.g., WMT), PPL would not converge to 1.0 but stay higher, reflecting language complexity.  \n",
        "- **No held-out test set**, so true generalization beyond toy examples cannot be assessed.  \n",
        "\n",
        "---\n",
        "\n",
        "## 5. Conclusions\n",
        "- Replication shows **RCTM2 with convolutional n-gram conditioning** captures translation mappings **without explicit alignments or attention**.  \n",
        "- Sharp reduction in loss & PPL supports the claim: **continuous representations mitigate sparsity** and encode **syntactic‚Äìsemantic information**.  \n",
        "- Correct French outputs demonstrate preservation of **word order, morphology, and semantics**.  \n",
        "- Confirms RCTMs‚Äô **historical role** as a transitional step from phrase-based SMT to neural sequence models (later advanced by Seq2Seq and Attention).  \n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ **In short:** Results mirror Kalchbrenner & Blunsom (2013) ‚Äî **low perplexity, syntactic‚Äìsemantic sensitivity, accurate translations**, though on a toy scale.\n"
      ],
      "metadata": {
        "id": "5SBVVDOcrDAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìä Comparative Analysis of Early Neural MT Models\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Abstract-Level\n",
        "- **RCTM (2013):** First fully neural MT model ‚Üí RNN decoder + convolutional encoders, no alignments.  \n",
        "- **Seq2Seq (2014):** Encoder‚Äìdecoder with LSTMs using a **fixed-length vector** as sentence representation.  \n",
        "- **Bahdanau (2015):** Solved the fixed-length bottleneck with **additive attention**, enabling dynamic context.  \n",
        "\n",
        "---\n",
        "\n",
        "## 2. Problem Addressed\n",
        "- **RCTM (2013):** Phrase-based SMT ‚Üí alignment dependency, sparsity, rigid phrase tables.  \n",
        "- **Seq2Seq (2014):** How to map **variable-length source ‚Üí variable-length target** end-to-end.  \n",
        "- **Bahdanau (2015):** Seq2Seq fails on long sentences (information bottleneck).  \n",
        "\n",
        "---\n",
        "\n",
        "## 3. Purposes\n",
        "- **RCTM:** Build continuous translation models without alignments.  \n",
        "- **Seq2Seq:** Show large LSTMs can directly learn MT, outperforming phrase-based SMT.  \n",
        "- **Bahdanau:** Improve long-sequence translation with **soft alignment** (attention).  \n",
        "\n",
        "---\n",
        "\n",
        "## 4. Methodology\n",
        "- **RCTM (2013):**\n",
        "  - Decoder: Recurrent Language Model (RNN).  \n",
        "  - Encoder: Convolutional Sentence Model (CSM) or Convolutional n-gram Model (CGM).  \n",
        "  - Continuous embeddings for sentences/phrases.  \n",
        "  - Explicit **Poisson model** for target length.  \n",
        "\n",
        "- **Seq2Seq (2014):**\n",
        "  - Encoder: deep LSTM encodes source ‚Üí fixed vector $v$.  \n",
        "  - Decoder: deep LSTM decodes word-by-word.  \n",
        "  - Trick: reverse input sentences for easier optimization.  \n",
        "\n",
        "- **Bahdanau (2015):**\n",
        "  - Encoder: bidirectional RNN ‚Üí sequence of annotations.  \n",
        "  - Decoder: RNN with **additive attention**.  \n",
        "  - Dynamic context vector:  \n",
        "    $$\n",
        "    c_t = \\sum_{j=1}^{T_x} \\alpha_{t,j} h_j\n",
        "    $$\n",
        "    with  \n",
        "    $$\n",
        "    \\alpha_{t,j} = \\frac{\\exp(e_{t,j})}{\\sum_k \\exp(e_{t,k})}, \\quad\n",
        "    e_{t,j} = v_a^\\top \\tanh(W_s s_{t-1} + W_h h_j)\n",
        "    $$  \n",
        "\n",
        "---\n",
        "\n",
        "## 5. Mathematical Core\n",
        "- **RCTM (2013):**\n",
        "  $$\n",
        "  P(f \\mid e) = \\prod_{i=1}^m P(f_i \\mid f_{1:i-1}, e)\n",
        "  $$  \n",
        "  with convolutional conditioning + Poisson length model.  \n",
        "\n",
        "- **Seq2Seq (2014):**\n",
        "  $$\n",
        "  P(y \\mid x) = \\prod_{t=1}^{T'} P(y_t \\mid v, y_{<t}), \\quad v = h_T\n",
        "  $$  \n",
        "\n",
        "- **Bahdanau (2015):**\n",
        "  $$\n",
        "  c_t = \\sum_{j=1}^{T_x} \\alpha_{t,j} h_j\n",
        "  $$  \n",
        "  $$\n",
        "  \\alpha_{t,j} = \\frac{\\exp(e_{t,j})}{\\sum_k \\exp(e_{t,k})}\n",
        "  $$  \n",
        "\n",
        "---\n",
        "\n",
        "## 6. Results\n",
        "- **RCTM:** 43% lower perplexity vs IBM alignment models; BLEU competitive (via rescoring).  \n",
        "- **Seq2Seq:** Outperformed phrase-based SMT on WMT‚Äô14 En‚ÜíFr (BLEU ‚âà 34.8 with ensemble).  \n",
        "- **Bahdanau:** Improved BLEU, esp. long sentences; introduced **attention heatmaps**.  \n",
        "\n",
        "---\n",
        "\n",
        "## 7. Limitations\n",
        "- **RCTM (2013):** No attention; CNN encoders less expressive; small dataset (~145k pairs).  \n",
        "- **Seq2Seq (2014):** Fixed-length bottleneck; forgetting early tokens; weak on long sequences.  \n",
        "- **Bahdanau (2015):** Computationally heavier; still RNN-based (later surpassed by Transformers).  \n",
        "\n",
        "---\n",
        "\n",
        "## 8. Historical Position\n",
        "- **RCTM (2013):** Prototype neural MT ‚Üí RNN decoder, CNN encoder.  \n",
        "- **Seq2Seq (2014):** Encoder‚Äìdecoder revolution, scalable to millions of pairs.  \n",
        "- **Bahdanau (2015):** Birth of **attention**, bridging toward Transformers (2017).  \n",
        "\n",
        "---\n",
        "\n",
        "## üìë Side-by-Side Table\n",
        "\n",
        "| **Aspect**      | **RCTM (2013)**             | **Seq2Seq (2014)**           | **Bahdanau (2015)**            |\n",
        "|------------------|-----------------------------|-------------------------------|--------------------------------|\n",
        "| **Encoder**      | CNN (sentence / n-gram)    | Deep LSTM                     | Bi-RNN                         |\n",
        "| **Decoder**      | RNN (RLM)                  | LSTM                          | LSTM + Attention               |\n",
        "| **Context**      | Convolutional embedding    | Final hidden state (fixed)    | Dynamic weighted sum (attention) |\n",
        "| **Target Length**| Explicit Poisson model     | Implicit                      | Implicit                       |\n",
        "| **Key Trick**    | Continuous representations | Reverse input                 | Additive attention              |\n",
        "| **Strength**     | Low perplexity, continuous | Strong BLEU, end-to-end       | Robust long-seq translation, interpretable alignments |\n",
        "| **Weakness**     | No attention, small data   | Bottleneck for long seqs      | Heavy computation               |\n",
        "| **Historical Role** | Early neural MT prototype | Seq2Seq paradigm              | Attention era ‚Üí Transformers    |\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ In Summary\n",
        "- **Kalchbrenner & Blunsom (2013):** Laid the **continuous representation foundation** for neural MT.  \n",
        "- **Sutskever et al. (2014):** Proved large RNNs could handle MT **end-to-end**.  \n",
        "- **Bahdanau et al. (2015):** Introduced **attention**, eliminating bottlenecks and paving the way to Transformers.  \n"
      ],
      "metadata": {
        "id": "8Y12Cw1IsFjB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üèóÔ∏è Evolution of Convolutions & Context in Translation\n",
        "\n",
        "---\n",
        "\n",
        "## 1. **Kalchbrenner & Blunsom (2013) ‚Äî RCTM**\n",
        "\n",
        "**Convolutional Sentence Model (CSM):**\n",
        "- 1D CNNs over embeddings.\n",
        "- Compress full sentence ‚Üí one vector.\n",
        "- Same vector used at every decoding step.\n",
        "\n",
        "# English sentence ‚Üí [CNN filters] ‚Üí Sentence vector ‚Üí RNN Decoder ‚Üí French words\n",
        "\n",
        "\n",
        "**Convolutional n-gram Model (CGM):**\n",
        "- CNN extracts local n-gram features.\n",
        "- Feed features step-by-step into decoder.\n",
        "- More dynamic than CSM, proto-attention-like.\n",
        "\n",
        "# English sentence ‚Üí [CNN n-gram features] ‚Üí Step-wise conditioning ‚Üí RNN Decoder ‚Üí French words\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 2. **Sutskever et al. (2014) ‚Äî Seq2Seq (No Attention)**\n",
        "\n",
        "- Encoder: deep LSTM.  \n",
        "- Compress source into **final hidden state** (fixed-length).  \n",
        "- Decoder: LSTM generates targets from this bottleneck.  \n",
        "\n",
        "# English sentence ‚Üí [LSTM Encoder] ‚Üí Final hidden state ‚Üí LSTM Decoder ‚Üí French words\n",
        "\n",
        "\n",
        "‚ùå Limitation: information bottleneck, poor on long sentences.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. **Bahdanau et al. (2015) ‚Äî Seq2Seq with Attention**\n",
        "\n",
        "- Encoder: bidirectional RNN produces annotations per source token.  \n",
        "- Decoder: computes **attention weights** each step.  \n",
        "- Builds a **dynamic context vector** per target word.  \n",
        "\n",
        "$$\n",
        "c_t = \\sum_{j=1}^{T_x} \\alpha_{t,j} h_j, \\quad\n",
        "\\alpha_{t,j} = \\frac{\\exp(e_{t,j})}{\\sum_k \\exp(e_{t,k})}, \\quad\n",
        "e_{t,j} = v_a^\\top \\tanh(W_s s_{t-1} + W_h h_j)\n",
        "$$\n",
        "\n",
        "# English sentence ‚Üí [BiRNN Encoder ‚Üí annotations]\n",
        "#‚Üì\n",
        "#Attention weights\n",
        "#‚Üì\n",
        "#Target LSTM step ‚Üê Dynamic context vector ‚Üí French word\n",
        "\n",
        "\n",
        "‚úÖ Benefits:  \n",
        "- Solves bottleneck.  \n",
        "- Handles long sequences.  \n",
        "- Provides interpretable alignments (attention heatmaps).  \n",
        "\n",
        "---\n",
        "\n",
        "## üìä Comparative Summary\n",
        "\n",
        "| **Model**            | **Encoder**             | **Context**                                       | **Decoder** | **Strength**                                  | **Limitation**                        |\n",
        "|-----------------------|-------------------------|---------------------------------------------------|-------------|-----------------------------------------------|---------------------------------------|\n",
        "| **RCTM (2013)**      | CNN (sentence / n-gram) | Fixed vector (CSM) or local n-gram features (CGM) | RNN (RLM)   | First continuous MT; no alignments needed      | No attention; small data; fixed-ish   |\n",
        "| **Seq2Seq (2014)**   | Deep LSTM               | Fixed final hidden state                          | LSTM        | End-to-end MT; strong BLEU vs SMT             | Bottleneck; weak on long sequences    |\n",
        "| **Bahdanau (2015)**  | Bi-RNN                  | Dynamic attention context                         | LSTM        | Robust to long seqs; interpretable alignments | More computationally expensive        |\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Key Insight\n",
        "- **RCTM (2013):** Convolutions encode source text ‚Üí global or local features.  \n",
        "- **Seq2Seq (2014):** End-to-end LSTM encoder‚Äìdecoder, but bottlenecked.  \n",
        "- **Bahdanau (2015):** Introduced **attention**, dynamic context ‚Üí foundation of Transformers (2017).  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vd0lUOM37g_b"
      }
    }
  ]
}