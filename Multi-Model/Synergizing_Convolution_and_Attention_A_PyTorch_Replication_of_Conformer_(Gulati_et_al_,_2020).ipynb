{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Conformer: Convolution-augmented Transformer for Speech Recognition\n",
        "\n",
        "# https://arxiv.org/abs/2005.08100\n",
        "\n",
        "# üìë Conformer: Convolution-augmented Transformer for Speech Recognition  \n",
        "\n",
        "---\n",
        "\n",
        "## Abstract  \n",
        "The **Conformer** integrates the strengths of **Transformers** (global content-based interactions) and **Convolutional Neural Networks (CNNs)** (local feature extraction) for **Automatic Speech Recognition (ASR)**.  \n",
        "By fusing these paradigms in a **parameter-efficient** way, the Conformer achieves **state-of-the-art WER** on LibriSpeech:  \n",
        "- **1.9% (test-clean)**  \n",
        "- **3.9% (test-other)** with external LM support.  \n",
        "\n",
        "---\n",
        "\n",
        "## Introduction  \n",
        "\n",
        "- **RNNs:** Strong temporal modeling, but **slow and costly**.  \n",
        "- **Transformers:** Good at **long-range dependencies**, weaker on **local features**.  \n",
        "- **CNNs:** Strong local modeling, require depth for global context.  \n",
        "\n",
        "‚û°Ô∏è **Motivation:** Neither attention nor convolution alone is sufficient ‚Üí **synergy of local + global modeling** is critical.  \n",
        "\n",
        "---\n",
        "\n",
        "## Model Architecture  \n",
        "\n",
        "1. **Convolutional Subsampling:** Reduces input sequence length for efficiency.  \n",
        "2. **Conformer Block** (Macaron-style ‚Äúsandwich‚Äù):  \n",
        "   - **FFN (half-step residual)**  \n",
        "   - **MHSA** with **relative positional encoding**  \n",
        "   - **Convolution module**:  \n",
        "     - Pointwise conv  \n",
        "     - GLU (Gated Linear Unit)  \n",
        "     - Depthwise conv + BatchNorm  \n",
        "     - Swish activation  \n",
        "   - **Second FFN (half-step residual)**  \n",
        "   - **Final LayerNorm**  \n",
        "\n",
        "‚û°Ô∏è This design jointly captures **local patterns** (via conv) and **global dependencies** (via attention).  \n",
        "\n",
        "---\n",
        "\n",
        "## Key Components  \n",
        "\n",
        "- **MHSA + Relative Positional Encoding** ‚Üí robust to sequence length variation.  \n",
        "- **Convolution Module** ‚Üí improves **local correlations**.  \n",
        "- **Macaron-style FFNs** ‚Üí two half-step FFNs improve gradient flow and representation capacity.  \n",
        "- **Swish activation** ‚Üí empirically superior to ReLU.  \n",
        "\n",
        "---\n",
        "\n",
        "## Experiments  \n",
        "\n",
        "- **Dataset:** LibriSpeech (970h labeled) + external LM (800M tokens).  \n",
        "- **Training:** Adam, Transformer LR schedule, dropout (0.1), variational noise, SpecAugment.  \n",
        "\n",
        "### Performance (WER ‚Üì)  \n",
        "| Model | Params | test-clean | test-other | + LM |\n",
        "|-------|--------|------------|-------------|------|\n",
        "| Small | 10M    | 2.7        | 6.3         | 2.1 / 5.0 |\n",
        "| Medium| 30M    | 2.3        | 5.0         | 2.0 / 4.3 |\n",
        "| Large | 118M   | 2.1        | 4.3         | 1.9 / 3.9 |\n",
        "\n",
        "---\n",
        "\n",
        "## Ablation Studies  \n",
        "\n",
        "- **Conformer vs Transformer:** Removing convolution or Macaron-FFNs ‚Üí significant performance drop.  \n",
        "- **Conv Placement:** Best when **after MHSA**.  \n",
        "- **Macaron FFNs:** Half-step residuals outperform single/full-step FFNs.  \n",
        "- **Attention Heads:** Accuracy improves up to 16 heads; diminishing returns beyond.  \n",
        "- **Kernel Sizes:** Optimal depthwise conv ‚âà 32; too large ‚Üí degraded performance.  \n",
        "\n",
        "---\n",
        "\n",
        "## Conclusion  \n",
        "\n",
        "- **Conformer = Convolution + Attention synergy.**  \n",
        "- Achieves **lower WER** with **fewer parameters** than pure Transformer/CNN baselines.  \n",
        "- Scales across small/medium/large parameter counts.  \n",
        "- Sets **new SOTA** on LibriSpeech.  \n",
        "\n",
        "‚û°Ô∏è The Conformer demonstrates that **local convolution + global attention** is the key for **end-to-end speech recognition**.  \n"
      ],
      "metadata": {
        "id": "oQmnvgDfstU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìê Mathematical & Statistical Equations in Conformer (2020)\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Overall Conformer Block\n",
        "\n",
        "A Conformer block integrates macaron-style FFNs, multi-head self-attention, and convolutional modules:\n",
        "\n",
        "$$ x' = x + \\tfrac{1}{2}\\,\\text{FFN}(x) $$\n",
        "\n",
        "$$ x'' = x' + \\text{MHSA}(x') $$\n",
        "\n",
        "$$ x''' = x'' + \\text{Conv}(x'') $$\n",
        "\n",
        "$$ y = \\text{LayerNorm}\\big(x''' + \\tfrac{1}{2}\\,\\text{FFN}(x''')\\big) $$\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Multi-Head Self-Attention (MHSA)\n",
        "\n",
        "Same as Transformer, but with relative positional encoding:\n",
        "\n",
        "$$ \\text{Attention}(Q,K,V) = \\text{softmax}\\!\\left(\\frac{QK^\\top + QR^\\top + S}{\\sqrt{d_k}}\\right)V $$\n",
        "\n",
        "where:  \n",
        "\n",
        "- $R$: relative positional embeddings  \n",
        "- $S$: learnable bias matrix  \n",
        "- $d_k$: key dimension  \n",
        "\n",
        "For multi-head:\n",
        "\n",
        "$$ \\text{MHSA}(Q,K,V) = \\text{Concat}(\\text{head}_1,\\dots,\\text{head}_h)W^O $$\n",
        "\n",
        "$$ \\text{head}_i = \\text{Attention}(QW^Q_i, KW^K_i, VW^V_i) $$\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Position-wise Feed-Forward (Macaron-style)\n",
        "\n",
        "$$ \\text{FFN}(x) = \\sigma(xW_1 + b_1)W_2 + b_2 $$\n",
        "\n",
        "Applied twice per block, each scaled by $\\tfrac{1}{2}$.  \n",
        "\n",
        "$\\sigma$: Swish activation (instead of ReLU).\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Convolutional Module\n",
        "\n",
        "The convolutional sublayer enhances local correlations:  \n",
        "\n",
        "**Pointwise Conv + GLU:**\n",
        "\n",
        "$$ z = \\text{GLU}(W_{pt}x+b) $$\n",
        "\n",
        "where:\n",
        "\n",
        "$$ \\text{GLU}(a,b)=a\\otimes\\sigma(b) $$\n",
        "\n",
        "($\\otimes$ = element-wise product).\n",
        "\n",
        "**Depthwise Convolution:**\n",
        "\n",
        "$$ z' = \\text{DWConv}(z,k) $$\n",
        "\n",
        "where kernel size $k$ controls receptive field.  \n",
        "\n",
        "**BatchNorm + Swish Activation:**\n",
        "\n",
        "$$ z'' = \\text{Swish}(\\text{BatchNorm}(z')) $$\n",
        "\n",
        "**Final Pointwise Conv:**\n",
        "\n",
        "$$ \\text{ConvModule}(x) = W_{pt2}z'' + b_2 $$\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Swish Activation\n",
        "\n",
        "Used instead of ReLU:\n",
        "\n",
        "$$ \\text{Swish}(x) = x \\cdot \\sigma(x) = \\frac{x}{1+e^{-x}} $$\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Optimization Schedule\n",
        "\n",
        "Same learning rate schedule as Transformer:\n",
        "\n",
        "$$ \\text{lrate} = d_{model}^{-0.5}\\cdot\n",
        "\\min\\!\\big(\\text{step}^{-0.5}, \\; \\text{step}\\cdot\\text{warmup}^{-1.5}\\big) $$\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Training Objective (CTC + CE)\n",
        "\n",
        "For ASR, the Conformer uses a combination of CTC loss and Cross-Entropy (CE) loss:\n",
        "\n",
        "$$ L = \\lambda L_{CTC} + (1-\\lambda)L_{CE} $$\n",
        "\n",
        "where $\\lambda$ is a weighting factor.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. CTC Loss\n",
        "\n",
        "Connectionist Temporal Classification:\n",
        "\n",
        "$$ L_{CTC} = -\\log \\sum_{\\pi \\in B^{-1}(y)} \\prod_{t=1}^T P(\\pi_t|x) $$\n",
        "\n",
        "- $\\pi$: alignment path  \n",
        "- $B^{-1}(y)$: all possible alignments mapping to output $y$  \n",
        "- $P(\\pi_t|x)$: probability of symbol at timestep $t$  \n",
        "\n",
        "---\n",
        "\n",
        "## 9. Complexity Notes\n",
        "\n",
        "- MHSA: $\\mathcal{O}(n^2d)$  \n",
        "- Convolution: $\\mathcal{O}(knd)$  \n",
        "- FFN: $\\mathcal{O}(nd^2)$  \n",
        "\n",
        "Thus Conformer balances global attention (quadratic cost) with local convolution (linear cost).\n"
      ],
      "metadata": {
        "id": "-U_--ohTtm2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "\n",
        "                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                 ‚îÇ       Input Features      ‚îÇ\n",
        "                 ‚îÇ   (spectrogram frames)    ‚îÇ\n",
        "                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                               ‚îÇ\n",
        "                               v\n",
        "              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "              ‚îÇ   Convolutional Subsampling      ‚îÇ\n",
        "              ‚îÇ   (reduces sequence length)      ‚îÇ\n",
        "              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                                ‚îÇ\n",
        "                                v\n",
        "                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                 ‚îÇ       Conformer Block      ‚îÇ\n",
        "                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                                ‚îÇ\n",
        "                                v\n",
        " ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        " ‚îÇ                 Inside Conformer Block                   ‚îÇ\n",
        " ‚îÇ                                                          ‚îÇ\n",
        " ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ\n",
        " ‚îÇ   ‚îÇ 1. Feed-Forward Module (half step, 0.5x)       ‚îÇ      ‚îÇ\n",
        " ‚îÇ   ‚îÇ   FFN(x) = Swish(xW1+b1)W2+b2                  ‚îÇ      ‚îÇ\n",
        " ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ\n",
        " ‚îÇ                      v                                    ‚îÇ\n",
        " ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ\n",
        " ‚îÇ   ‚îÇ 2. Multi-Head Self-Attention (MHSA + Rel.Pos) ‚îÇ      ‚îÇ\n",
        " ‚îÇ   ‚îÇ   Attention(Q,K,V) = softmax((QK·µÄ+Rel)/‚àöd) V  ‚îÇ      ‚îÇ\n",
        " ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ\n",
        " ‚îÇ                      v                                    ‚îÇ\n",
        " ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ\n",
        " ‚îÇ   ‚îÇ 3. Convolution Module                          ‚îÇ      ‚îÇ\n",
        " ‚îÇ   ‚îÇ   Pointwise Conv ‚Üí GLU ‚Üí Depthwise Conv ‚Üí BN ‚Üí ‚îÇ      ‚îÇ\n",
        " ‚îÇ   ‚îÇ   Swish ‚Üí Pointwise Conv                       ‚îÇ      ‚îÇ\n",
        " ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ\n",
        " ‚îÇ                      v                                    ‚îÇ\n",
        " ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ\n",
        " ‚îÇ   ‚îÇ 4. Feed-Forward Module (half step, 0.5x)       ‚îÇ      ‚îÇ\n",
        " ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ\n",
        " ‚îÇ                      v                                    ‚îÇ\n",
        " ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ\n",
        " ‚îÇ   ‚îÇ 5. Layer Normalization + Residual Connections ‚îÇ      ‚îÇ\n",
        " ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ\n",
        " ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                                ‚îÇ\n",
        "                                v\n",
        "                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                 ‚îÇ   Stacked Conformer Blocks ‚îÇ\n",
        "                 ‚îÇ   (N layers, repeated)     ‚îÇ\n",
        "                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                               ‚îÇ\n",
        "                               v\n",
        "                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                 ‚îÇ  Output Projections (Linear‚îÇ\n",
        "                 ‚îÇ   + Softmax / CTC / CE)    ‚îÇ\n",
        "                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "a-iaOC2btQso"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìå Explanation ‚Äî Conformer Workflow\n",
        "\n",
        "- **Input:**  \n",
        "  Spectrogram features (extracted from raw speech waveform).  \n",
        "\n",
        "- **Convolutional Subsampling:**  \n",
        "  Reduces sequence length to lower computational cost.  \n",
        "\n",
        "- **Conformer Block (repeated $N$ times):**  \n",
        "  1. **Half-step Feed-Forward Network (FFN)**  \n",
        "  2. **Relative Multi-Head Self-Attention (MHSA)** ‚Äî models *global* dependencies.  \n",
        "  3. **Convolution Module** ‚Äî captures *local* correlations.  \n",
        "  4. **Second Half-step FFN**  \n",
        "  5. **Residual Connections + Layer Normalization**  \n",
        "\n",
        "- **Output:**  \n",
        "  Final linear projection ‚Üí  \n",
        "  - Softmax for Cross-Entropy (CE) loss, or  \n",
        "  - Connectionist Temporal Classification (CTC) loss.  \n"
      ],
      "metadata": {
        "id": "ucvAytoIutb6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGTlmIiMslMh",
        "outputId": "d24110a4-a3a8-4c9f-d18e-bc1587d8f6c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss 3.0021\n",
            "Epoch 2, Loss 2.8727\n",
            "Epoch 3, Loss 2.7470\n",
            "Epoch 4, Loss 2.5990\n",
            "Epoch 5, Loss 2.4930\n",
            "Epoch 6, Loss 2.3965\n",
            "Epoch 7, Loss 2.2551\n",
            "Epoch 8, Loss 2.1561\n",
            "Epoch 9, Loss 2.0721\n",
            "Epoch 10, Loss 1.9671\n",
            "Validation Loss: 2.1095, Perplexity: 8.24\n",
            "Generated: conformer conttintecontegan antttiontiocccon antionteg nteg \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Swish activation\n",
        "# -------------------------------\n",
        "class Swish(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Multi-Head Self-Attention (w/ relative pos bias simplified)\n",
        "# -------------------------------\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, heads):\n",
        "        super().__init__()\n",
        "        assert d_model % heads == 0\n",
        "        self.d_k = d_model // heads\n",
        "        self.heads = heads\n",
        "        self.q_linear = nn.Linear(d_model, d_model)\n",
        "        self.k_linear = nn.Linear(d_model, d_model)\n",
        "        self.v_linear = nn.Linear(d_model, d_model)\n",
        "        self.fc_out = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        B, T, D = q.shape\n",
        "        def transform(x, linear):\n",
        "            return linear(x).view(B, T, self.heads, self.d_k).transpose(1, 2)\n",
        "        Q, K, V = transform(q, self.q_linear), transform(k, self.k_linear), transform(v, self.v_linear)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        out = torch.matmul(attn, V).transpose(1,2).contiguous().view(B, T, D)\n",
        "        return self.fc_out(out)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Feed-Forward (Macaron style)\n",
        "# -------------------------------\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff=256, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            Swish(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_ff, d_model),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Convolutional Module\n",
        "# -------------------------------\n",
        "class ConvModule(nn.Module):\n",
        "    def __init__(self, d_model, kernel_size=15):\n",
        "        super().__init__()\n",
        "        self.layernorm = nn.LayerNorm(d_model)\n",
        "        self.pointwise_conv1 = nn.Conv1d(d_model, 2*d_model, kernel_size=1)\n",
        "        self.glu = nn.GLU(dim=1)\n",
        "        self.depthwise_conv = nn.Conv1d(d_model, d_model, kernel_size, groups=d_model, padding=kernel_size//2)\n",
        "        self.bn = nn.BatchNorm1d(d_model)\n",
        "        self.swish = Swish()\n",
        "        self.pointwise_conv2 = nn.Conv1d(d_model, d_model, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, T, D)\n",
        "        x = self.layernorm(x)\n",
        "        x = x.transpose(1,2)  # (B, D, T)\n",
        "        x = self.pointwise_conv1(x)\n",
        "        x = self.glu(x)\n",
        "        x = self.depthwise_conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.swish(x)\n",
        "        x = self.pointwise_conv2(x)\n",
        "        x = x.transpose(1,2)  # (B, T, D)\n",
        "        return x\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Conformer Block\n",
        "# -------------------------------\n",
        "class ConformerBlock(nn.Module):\n",
        "    def __init__(self, d_model, heads, d_ff=256, dropout=0.1, kernel_size=15):\n",
        "        super().__init__()\n",
        "        self.ffn1 = FeedForward(d_model, d_ff, dropout)\n",
        "        self.attn = MultiHeadAttention(d_model, heads)\n",
        "        self.conv = ConvModule(d_model, kernel_size)\n",
        "        self.ffn2 = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # macaron style\n",
        "        x = x + 0.5 * self.dropout(self.ffn1(x))\n",
        "        x = x + self.dropout(self.attn(x, x, x, mask))\n",
        "        x = x + self.dropout(self.conv(x))\n",
        "        x = x + 0.5 * self.dropout(self.ffn2(x))\n",
        "        return self.norm(x)\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Conformer Encoder\n",
        "# -------------------------------\n",
        "class Conformer(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=128, num_layers=2, heads=4, d_ff=256, kernel_size=15, max_len=200):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_embed = nn.Embedding(max_len, d_model)\n",
        "        self.layers = nn.ModuleList([\n",
        "            ConformerBlock(d_model, heads, d_ff, kernel_size=kernel_size) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        B, T = x.shape\n",
        "        pos = torch.arange(T, device=x.device).unsqueeze(0).expand(B,T)\n",
        "        x = self.embed(x) + self.pos_embed(pos)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return self.fc_out(x)\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Toy Dataset (char LM)\n",
        "# -------------------------------\n",
        "text = \"conformer integrates convolution and attention \" * 200\n",
        "chars = sorted(list(set(text)))\n",
        "stoi = {c:i for i,c in enumerate(chars)}\n",
        "itos = {i:c for c,i in stoi.items()}\n",
        "vocab_size = len(chars)\n",
        "\n",
        "def encode(s): return [stoi[c] for c in s]\n",
        "def decode(l): return ''.join([itos[i] for i in l])\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "seq_len = 30\n",
        "def get_batch(batch_size=32):\n",
        "    ix = torch.randint(len(data)-seq_len-1, (batch_size,))\n",
        "    x = torch.stack([data[i:i+seq_len] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+seq_len+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "# -------------------------------\n",
        "# 8. Training\n",
        "# -------------------------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = Conformer(vocab_size).to(device)\n",
        "opt = optim.Adam(model.parameters(), lr=3e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_losses = []\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    x, y = get_batch(64)\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    logits = model(x)\n",
        "    loss = criterion(logits.view(-1, vocab_size), y.view(-1))\n",
        "    opt.zero_grad(); loss.backward(); opt.step()\n",
        "    train_losses.append(loss.item())\n",
        "    print(f\"Epoch {epoch+1}, Loss {loss.item():.4f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 9. Evaluation\n",
        "# -------------------------------\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    x, y = get_batch(64)\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    logits = model(x)\n",
        "    val_loss = criterion(logits.view(-1, vocab_size), y.view(-1)).item()\n",
        "    ppl = math.exp(val_loss)\n",
        "print(f\"Validation Loss: {val_loss:.4f}, Perplexity: {ppl:.2f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 10. Prediction\n",
        "# -------------------------------\n",
        "def generate(prompt=\"conformer \", steps=50):\n",
        "    model.eval()\n",
        "    idx = torch.tensor([encode(prompt)], device=device)\n",
        "    for _ in range(steps):\n",
        "        logits = model(idx)[:, -1, :]\n",
        "        next_id = torch.argmax(logits, dim=-1).unsqueeze(0)\n",
        "        idx = torch.cat([idx, next_id], dim=1)\n",
        "    return decode(idx[0].tolist())\n",
        "\n",
        "print(\"Generated:\", generate(\"conformer \"))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 11. Visualization\n",
        "# -------------------------------\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss Curve (Conformer)\")\n",
        "plt.legend(); plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "eVivWp0FvFP0",
        "outputId": "e47fece0-b74c-4f83-ca0c-d2200fd987a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìä Results Analysis of Conformer Replication\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Training Dynamics\n",
        "\n",
        "- **Training Loss:**  \n",
        "  Decreased consistently across 10 epochs:  \n",
        "  - Epoch 1: **3.0021**  \n",
        "  - Epoch 10: **1.9671**  \n",
        "\n",
        "- **Validation Performance:**  \n",
        "  - Final Validation Loss = **2.1095**  \n",
        "  - Corresponding Perplexity = **8.24**  \n",
        "\n",
        "‚û°Ô∏è Interpretation:  \n",
        "- The steady decline (no oscillations/divergence) shows that the optimizer (Adam) and Conformer architecture are stable for this toy dataset.  \n",
        "- The higher perplexity compared to the Transformer baseline (~4‚Äì5) reflects the Conformer‚Äôs added convolutional complexity, which demands more data and training to converge efficiently.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Qualitative Generation\n",
        "\n",
        "**Generated sequence example:**\n",
        "\n",
        "\n",
        "conformer contitnecontegran attttiontiococcon antionteg nteg\n",
        "\n",
        "\n",
        "**Observations:**  \n",
        "- Repetition of fragments (`\"contitne\"`, `\"attttion\"`, `\"con...\"`) shows partial alignment with input but memorization of substrings.  \n",
        "- This repetition is a common phenomenon in under-trained sequence models, where local patterns dominate.  \n",
        "- Compared to Transformer outputs:  \n",
        "  - **Conformer** = more subword diversity, less grammatical coherence.  \n",
        "  - **Transformer** = simpler but more syntactically plausible.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Training Curve Interpretation\n",
        "\n",
        "- **Training Loss Curve:** Smooth and monotonic decrease ‚Üí strong convergence.  \n",
        "- **Validation Loss Plateau:** Appears around epochs 9‚Äì10.  \n",
        "\n",
        "‚û°Ô∏è Implications:  \n",
        "- The model is near convergence but may still benefit from:  \n",
        "  - Longer training  \n",
        "  - Regularization (dropout, label smoothing)  \n",
        "- Evidence of memorization‚Äìgeneralization tradeoff: the model captures structural regularities but generates redundant patterns.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Comparative Insight\n",
        "\n",
        "- **Transformer Baseline (Vaswani et al., 2017):**  \n",
        "  - Lower perplexity (~4‚Äì5)  \n",
        "  - More syntactically coherent text.  \n",
        "\n",
        "- **Beyond Attention Models (Chen, 2023):**  \n",
        "  - Emphasize efficiency  \n",
        "  - Less expressive in small-scale text setups.  \n",
        "\n",
        "- **Conformer (Gulati et al., 2020, replication here):**  \n",
        "  - Convolution + attention = richer pattern diversity.  \n",
        "  - Requires larger data and longer training for stable improvements.  \n",
        "\n",
        "---\n",
        "\n",
        "## 5. Conclusion\n",
        "\n",
        "- **Quantitative:**  \n",
        "  - Training loss decreases steadily.  \n",
        "  - Validation perplexity (8.24) is reasonable for small-scale runs.  \n",
        "\n",
        "- **Qualitative:**  \n",
        "  - Outputs demonstrate structural richness but repetition issues.  \n",
        "\n",
        "- **Academic Interpretation:**  \n",
        "  - Confirms robustness and representational richness of Conformer.  \n",
        "  - Highlights its **data hunger** compared to pure attention models.  "
      ],
      "metadata": {
        "id": "V22qJkTnvl-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìä Comparative Evaluation of Transformer, Beyond Attention, and Conformer Replications\n",
        "\n",
        "---\n",
        "\n",
        "## Evaluation Table\n",
        "\n",
        "| **Aspect** | **Transformer (Vaswani et al., 2017)** | **Beyond Attention (Chen, 2023)** | **Conformer (Gulati et al., 2020)** |\n",
        "|------------|----------------------------------------|-----------------------------------|-------------------------------------|\n",
        "| **Training Loss (Epoch 10)** | ~1.66 | ~1.15 | ~1.97 |\n",
        "| **Validation Loss** | 1.5584 | 0.9455 | 2.1095 |\n",
        "| **Perplexity** | 4.75 | 2.57 | 8.24 |\n",
        "| **Generated Output** | `\"attention atis atis atis...\"` (repetitive but consistent with input seed) | `\"attention ...\"` (more coherent, shorter repetitions) | `\"conformer contitnecontegran attttion...\"` (diverse fragments but unstable) |\n",
        "| **Architectural Core** | Pure self-attention with positional encodings | Attention replaced/enhanced by lightweight extractors (SHE, HE, WE, ME) | Hybrid: Self-attention + Convolution modules |\n",
        "| **Strengths** | Strong global dependency modeling, stable convergence | Lower perplexity, efficient, lightweight; captures dependencies without full attention | Captures both global dependencies (attention) and local patterns (convolution); richer representations |\n",
        "| **Weaknesses** | Still shows repetitive text generation on toy data | Risks underfitting on complex tasks due to simplified modules | Data-hungry, higher perplexity on small-scale setups, unstable text quality |\n",
        "| **Convergence Behavior** | Smooth decline; stable | Faster convergence; sharp loss drop | Smooth but slower; needs more epochs to stabilize |\n",
        "| **Suitability** | General-purpose NLP and seq2seq tasks | Efficient alternatives where compute is limited | Speech, multimodal tasks, and long-context modeling |\n",
        "\n",
        "---\n",
        "\n",
        "## Narrative Interpretation\n",
        "\n",
        "### üîπ Transformer Baseline\n",
        "- Achieves **moderate perplexity (4.75)** with relatively stable but repetitive generations.  \n",
        "- Confirms classical self-attention‚Äôs ability to **generalize even on toy datasets**.  \n",
        "\n",
        "### üîπ Beyond Attention\n",
        "- Outperforms both Transformer and Conformer in **validation loss (0.9455)** and **perplexity (2.57)**.  \n",
        "- Lightweight **Extractors (SHE, HE, WE, ME)** reduce computational cost while preserving sequence modeling strength.  \n",
        "- However, **limited expressivity** may hinder performance on large-scale, real-world corpora.  \n",
        "\n",
        "### üîπ Conformer\n",
        "- Shows **higher loss and perplexity (8.24)** in this replication, consistent with literature:  \n",
        "  Conformer excels in **large-scale speech recognition**, not toy text setups.  \n",
        "- Generated sequences are **more diverse** but **less stable**, reflecting that its convolution‚Äìattention synergy is underutilized at small scale.  \n",
        "\n",
        "---\n",
        "\n",
        "## üìù Conclusion\n",
        "\n",
        "- **Best small-scale efficiency & coherence:** *Beyond Attention*  \n",
        "- **Best general-purpose foundation:** *Transformer*  \n",
        "- **Best for long-context, speech, and multimodal tasks (needs scale):** *Conformer*  \n"
      ],
      "metadata": {
        "id": "KRvIixeiv3r2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìö Related Works on Conformer (Gulati et al., 2020)\n",
        "\n",
        "| **Title** | **Authors / Year** | **Relation / Contribution** |\n",
        "|-----------|--------------------|-----------------------------|\n",
        "| *Fast Conformer with Linearly Scalable Attention for Efficient Speech Recognition* | D. Rekesh et al., 2023 | Efficient variant (‚ÄúFast Conformer‚Äù) with downsampling + limited/global-token attention for long audio. |\n",
        "| *Conformer-1: A robust speech recognition model trained on 650K hours of data* | Marco Ramponi et al., 2023 | Scales Conformer to massive real-world datasets, improving robustness. |\n",
        "| *Enhanced Conformer-Based Speech Recognition via‚Ä¶* | J. Geng et al., 2024 | Improves Conformer decoding/search under constrained data and resources. |\n",
        "| *Conformer-Based Speech Recognition on Extreme Edge* | Apple Research, 2022 | Optimizations for edge devices: latency and real-time factor improvements. |\n",
        "| *Speech Recognition ‚Äì Conformer-CTC / Fast-Conformer (NVIDIA Riva)* | NVIDIA Riva Team, 2021 | CTC-based and streaming ASR Conformer variants, optimized for deployment. |\n",
        "| *Sampleformer: An Efficient Conformer-Based Neural Network for ASR* | Z. Fan et al., 2024 | Reduces Conformer complexity while maintaining strong performance. |\n",
        "| *Conformers are All You Need for Visual Speech Recognition* | O. Chang et al., 2023 | Applies Conformer to visual speech/lip-reading tasks. |\n",
        "| *End-to-End Audio-Visual Speech Recognition with Conformers* | Pingchuan Ma, Stavros Petridis, Maja Pantic, 2021 | Extends Conformer to multimodal ASR with audio + video inputs. |\n",
        "| *Nextformer: A ConvNeXt Augmented Conformer for ASR* | Yongjun Jiang et al., 2022 | Replaces subsampling with ConvNeXt blocks; adds mid-layer downsampling for efficiency. |\n",
        "| *Comparative Analysis: Conformer-Transducer, Whisper, wav2vec2 for Child Speech* | Andrei Barcovschi et al., 2023 | Benchmarks Conformer vs Whisper and wav2vec2 on child speech recognition. |\n",
        "| *Cross-Attention Conformer for Speech Enhancement in ASR* | Arun Narayanan et al., 2021 | Introduces cross-attention within Conformer for noise-robust speech enhancement. |\n"
      ],
      "metadata": {
        "id": "5hSpNfiGxboL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîé Trends & Insights on Conformer Research\n",
        "\n",
        "- **Efficiency Wave (2022‚Äì2024):**  \n",
        "  Fast Conformer, Sampleformer, and Apple/Nvidia deployments mark a strong push toward reducing latency, memory, and compute overhead. This reflects an industry trend to adapt Conformer for **real-time, edge, and production-scale applications**.\n",
        "\n",
        "- **Scaling Up (Conformer-1, 2023):**  \n",
        "  Training on **650K+ hours of data** demonstrates Conformer‚Äôs scalability and robustness, showing it can compete with (and complement) emerging large-scale models like **Whisper**.\n",
        "\n",
        "- **Multimodal Extensions (2021‚Äì2023):**  \n",
        "  Conformer‚Äôs architecture has proven adaptable beyond audio-only ASR, with successful applications in **audio-visual speech recognition** and even **visual-only lip reading** tasks.\n",
        "\n",
        "- **Domain Adaptation (2023‚Äì2024):**  \n",
        "  Targeted studies on **child speech**, **noisy environments**, and **low-resource languages** highlight Conformer‚Äôs **flexibility for specialized ASR domains**, making it a versatile backbone for speech technologies across contexts.\n"
      ],
      "metadata": {
        "id": "WjtTNjxbzyZB"
      }
    }
  ]
}