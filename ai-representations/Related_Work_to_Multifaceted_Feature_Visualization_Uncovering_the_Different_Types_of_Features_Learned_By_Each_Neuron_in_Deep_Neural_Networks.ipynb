{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Related Work to *Multifaceted Feature Visualization: Uncovering the Different Types of Features Learned By Each Neuron in Deep Neural Networks*\n",
        "\n",
        "\n",
        "| **Author(s)** | **Year** | **Title** | **Venue / Type** | **Relation to MFV** |\n",
        "|---------------|----------|-----------|------------------|---------------------|\n",
        "| Nguyen, Yosinski, Clune | 2016 | *Multifaceted Feature Visualization: Uncovering the Different Types of Features Learned by Each Neuron in Deep Neural Networks* | arXiv | **Origin paper**; introduces the MFV framework and formalizes neuron multimodality. |\n",
        "| Nguyen et al. | 2016 | *Synthesizing the Preferred Inputs for Neurons in Neural Networks via Deep Generator Networks* | NeurIPS | Uses generative priors for activation maximization; complements MFV by improving realism, but does not address multimodality explicitly. |\n",
        "| Xia et al. | 2016 | *Every Filter Extracts a Specific Texture in CNNs* | arXiv | Argues for texture specificity of filters; MFV challenges strict single-feature interpretations by revealing multiple facets per neuron. |\n",
        "| Yosinski et al. | 2015 | *Understanding Neural Networks Through Deep Visualization* | ICML Workshop | Introduces optimization-based visualization techniques that MFV extends with facet separation. |\n",
        "| Li | 2016 | *Visualization of Deep Convolutional Neural Networks* | PhD Thesis | Broad overview of CNN visualization techniques; MFV fits within feature visualization methods. |\n",
        "| Nguyen, Yosinski, Clune | 2019 | *Understanding Neural Networks via Feature Visualization: A Survey* | arXiv | Synthesizes visualization literature; positions MFV as a key method addressing neuron multimodality. |\n",
        "| Mahendran, Vedaldi | 2015 | *Visualizing Deep CNNs Using Natural Pre-images* | CVPR | Introduces inversion and natural-image priors; MFV instead focuses on separating activation modes. |\n",
        "| Hada, Carreira-Perpiñán | 2019 | *Sampling the Inverse Set of a Neuron* | arXiv | Explores neuron inverse sets; aligns with MFV’s view of multimodal activation landscapes. |\n",
        "| Rozsa et al. | 2017 | *Exploring LOTS in Deep Neural Networks* | CVPR Workshop | Studies neuron sensitivity; MFV provides visual evidence of multiple response modes. |\n",
        "| Binder et al. | 2016 | *Layer-Wise Relevance Propagation* | PLOS ONE | Attribution-based interpretability; complementary to MFV’s synthesis-based approach. |\n",
        "| Punjabi, Katsaggelos | 2017 | *Visualization of Feature Evolution During CNN Training* | ICIP | Focuses on temporal evolution; MFV focuses on neuron semantics at convergence. |\n",
        "| Luo et al. | 2015 | *Foveation-based Mechanisms Alleviate Adversarial Examples* | NIPS Workshop | Shows spatial sensitivity effects; MFV exploits spatial structure in neuron activations. |\n",
        "| Zintgraf et al. | 2016 | *A New Method to Visualize Deep Neural Networks* | ICML Workshop | Perturbation-based explanations; contrasts with MFV’s optimization-based synthesis. |\n",
        "| Zintgraf et al. | 2017 | *Prediction Difference Analysis* | ICLR | Decision-focused explanations; MFV is representation-focused. |\n",
        "| Kobayashi et al. | 2017 | *GAN for Visualizing Convolutional Networks* | IJCNN | Uses GANs for visualization; MFV does not require external generators. |\n",
        "| Wei et al. | 2015 | *Understanding Intra-Class Knowledge Inside CNN* | CVPR | Analyzes intra-class variation; MFV reveals intra-neuron variation. |\n",
        "| Samek et al. | 2015 | *Evaluating the Visualization of What a DNN Has Learned* | IEEE TPAMI | Evaluation of visualization reliability; MFV improves interpretability quality. |\n",
        "| Mahendran, Vedaldi | 2014 | *Understanding Deep Image Representations by Inverting Them* | CVPR | Early inversion work; MFV focuses on neuron-level multimodality. |\n",
        "| Stergiou | 2021 | *The Mind’s Eye: Visualizing Class-Agnostic Features of CNNs* | arXiv | Class-agnostic feature visualization; conceptually aligned with MFV. |\n",
        "| Fu et al. | 2018 | *Visualizing CNNs with Gradient Information* | Neurocomputing | Gradient-based methods; MFV restructures gradient optimization via clustering. |\n",
        "| He et al. | 2016 | *A Powerful Generative Model Using Random Weights* | NeurIPS | Explores representational priors; MFV focuses on neuron semantics. |\n",
        "| Seo et al. | 2018 | *Regional Multi-Scale Explanations of DNNs* | ECCV Workshops | Improves visual coherence; MFV introduces center-biased regularization for similar goals. |\n",
        "| Li et al. | 2015 | *Convergent Learning* | NeurIPS | Studies representation similarity across networks; MFV studies multiplicity within neurons. |\n",
        "| Gu, Tresp | 2019 | *Semantics for Global and Local Interpretation* | arXiv | Semantic interpretation framework; MFV provides concrete neuron-level semantics. |\n",
        "| Nekhaev, Demin | 2017 | *Deconvolutional Optimization for Neuron Visualization* | arXiv | Alternative optimization strategies; MFV emphasizes multimodal structure. |\n",
        "| Qin et al. | 2018 | *How CNNs See the World: A Survey* | arXiv | Comprehensive survey; MFV is a core contribution in neuron visualization. |\n",
        "| Olah et al. | 2018 | *The Building Blocks of Interpretability* | Distill | Conceptual framework; MFV provides neuron-level building blocks. |\n",
        "| Alsallakh et al. | 2018 | *Understanding Error Structure in CNNs* | CVPR | Error-driven interpretability; MFV is representation-driven. |\n",
        "| Valle et al. | 2020 | *Assessing Reliability of Visual Explanations* | AAAI | Evaluates robustness of explanations; MFV improves fidelity through facet separation. |\n",
        "| Bau et al. | 2017 | *Network Dissection* | CVPR | Quantifies neuron interpretability; MFV reveals hidden multifaceted semantics beyond single labels. |\n",
        "| Dabkowski, Gal | 2017 | *Real-Time Image Saliency* | NeurIPS | Saliency-based explanation; complementary to MFV. |\n",
        "| Fong, Vedaldi | 2017 | *Meaningful Perturbations* | ICCV | Perturbation explanations; MFV uses synthesis instead. |\n",
        "| Wang et al. | 2018 | *Alternating Blurring/Deblurring Visualization* | Pattern Recognition | Addresses artifacts; MFV addresses mode collapse. |\n",
        "| Hohman et al. | 2018 | *Visual Analytics in Deep Learning* | IEEE CG&A | Survey of visual analytics; MFV contributes a neuron-centric method. |\n",
        "| Nie et al. | 2018 | *Theoretical Explanation for Visualization Artifacts* | ICML | Explains gradient artifacts; MFV mitigates them via data-driven initialization. |\n",
        "| Guo et al. | 2018 | *Neural Network Interpretation via Textual Summarization* | AAAI | Text-based explanations; MFV is visual and neuron-level. |\n",
        "| Nguyen et al. | 2014 | *Deep Neural Networks Are Easily Fooled* | CVPR | Shows unrealistic maximizers; directly motivates MFV regularization. |\n",
        "| Engstrom et al. | 2019 | *Adversarial Robustness as a Prior* | ICML | Robustness as representation prior; MFV focuses on interpretability. |\n",
        "| Dosovitskiy, Brox | 2016 | *Generating Images with Perceptual Similarity Metrics* | NeurIPS | Perceptual losses; complementary to MFV optimization. |\n",
        "| Olah et al. | 2020 | *Zoom In: An Introduction to Circuits* | Distill | Circuit-level interpretability; MFV operates at neuron level but aligns conceptually. |\n",
        "\n",
        "---\n",
        "\n",
        "## Synthesis\n",
        "\n",
        "This body of work shows that:\n",
        "\n",
        "- **Activation maximization is powerful but prone to averaging and artifacts**.  \n",
        "- **Neurons encode rich, distributed, and abstract representations** rather than single concepts.  \n",
        "- **Most prior visualization methods lack mechanisms to separate activation modes** within a neuron.\n",
        "\n",
        "**Multifaceted Feature Visualization** advances the field by reframing neuron visualization as a **mode-discovery problem** and introducing a systematic, data-driven pipeline that reveals multiple distinct facets per neuron, thereby providing a more faithful picture of internal neural representations.\n"
      ],
      "metadata": {
        "id": "bHcbJ1MX4S2Q"
      }
    }
  ]
}